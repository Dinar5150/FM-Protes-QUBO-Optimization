{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5iiG66oyoQqP"
      },
      "source": [
        "requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2hTOMw3woTDV",
        "outputId": "5c61305f-233e-4e2e-b3c2-244fc2f682ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: dimod in /usr/local/lib/python3.12/dist-packages (0.12.21)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.12/dist-packages (from dimod) (2.0.1)\n",
            "Requirement already satisfied: dwave-neal in /usr/local/lib/python3.12/dist-packages (0.6.0)\n",
            "Requirement already satisfied: dwave-samplers<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from dwave-neal) (1.7.0)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.21.6 in /usr/local/lib/python3.12/dist-packages (from dwave-samplers<2.0.0,>=1.0.0->dwave-neal) (2.0.1)\n",
            "Requirement already satisfied: dimod<0.13.0,>=0.12.21 in /usr/local/lib/python3.12/dist-packages (from dwave-samplers<2.0.0,>=1.0.0->dwave-neal) (0.12.21)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.12/dist-packages (from dwave-samplers<2.0.0,>=1.0.0->dwave-neal) (3.6.1)\n",
            "Requirement already satisfied: protes==0.3.12 in /usr/local/lib/python3.12/dist-packages (0.3.12)\n",
            "Requirement already satisfied: jax<0.5.0,>=0.4.13 in /usr/local/lib/python3.12/dist-packages (from jax[cpu]<0.5.0,>=0.4.13; python_version > \"3.9\"->protes==0.3.12) (0.4.38)\n",
            "Requirement already satisfied: matplotlib>=3.7.0 in /usr/local/lib/python3.12/dist-packages (from protes==0.3.12) (3.10.0)\n",
            "Requirement already satisfied: numpy<2.0.2,>=1.22 in /usr/local/lib/python3.12/dist-packages (from protes==0.3.12) (2.0.1)\n",
            "Requirement already satisfied: optax>=0.1.4 in /usr/local/lib/python3.12/dist-packages (from protes==0.3.12) (0.2.5)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.12/dist-packages (from protes==0.3.12) (1.16.3)\n",
            "Requirement already satisfied: seaborn>=0.12.2 in /usr/local/lib/python3.12/dist-packages (from protes==0.3.12) (0.13.2)\n",
            "Requirement already satisfied: jaxlib<=0.4.38,>=0.4.38 in /usr/local/lib/python3.12/dist-packages (from jax<0.5.0,>=0.4.13->jax[cpu]<0.5.0,>=0.4.13; python_version > \"3.9\"->protes==0.3.12) (0.4.38)\n",
            "Requirement already satisfied: ml_dtypes>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from jax<0.5.0,>=0.4.13->jax[cpu]<0.5.0,>=0.4.13; python_version > \"3.9\"->protes==0.3.12) (0.5.4)\n",
            "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.12/dist-packages (from jax<0.5.0,>=0.4.13->jax[cpu]<0.5.0,>=0.4.13; python_version > \"3.9\"->protes==0.3.12) (3.4.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.0->protes==0.3.12) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.0->protes==0.3.12) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.0->protes==0.3.12) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.0->protes==0.3.12) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.0->protes==0.3.12) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.0->protes==0.3.12) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.0->protes==0.3.12) (3.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.0->protes==0.3.12) (2.9.0.post0)\n",
            "Requirement already satisfied: absl-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from optax>=0.1.4->protes==0.3.12) (1.4.0)\n",
            "Requirement already satisfied: chex>=0.1.87 in /usr/local/lib/python3.12/dist-packages (from optax>=0.1.4->protes==0.3.12) (0.1.90)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.12/dist-packages (from seaborn>=0.12.2->protes==0.3.12) (2.2.2)\n",
            "Requirement already satisfied: typing_extensions>=4.2.0 in /usr/local/lib/python3.12/dist-packages (from chex>=0.1.87->optax>=0.1.4->protes==0.3.12) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from chex>=0.1.87->optax>=0.1.4->protes==0.3.12) (75.2.0)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from chex>=0.1.87->optax>=0.1.4->protes==0.3.12) (0.12.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.2->seaborn>=0.12.2->protes==0.3.12) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.2->seaborn>=0.12.2->protes==0.3.12) (2025.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.7.0->protes==0.3.12) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "%pip install dimod\n",
        "%pip install dwave-neal\n",
        "%pip install protes==0.3.12"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xys2C6t24M-L"
      },
      "source": [
        "DynamicMatrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "o6GeCAip3bbF"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "def select_k_from_n(self,n: int, k: int,rng: np.random.Generator) -> list[int]:\n",
        "        selected = []\n",
        "        remaining_slots = k\n",
        "        for i in range(n):\n",
        "            prob_select = remaining_slots / (n - i)\n",
        "            if rng.random() < prob_select:\n",
        "                selected.append(i)\n",
        "                remaining_slots -= 1\n",
        "\n",
        "                if remaining_slots == 0:\n",
        "                    break\n",
        "        return selected\n",
        "class DynamicMatrix:\n",
        "    def __init__(self, initial_n=1):\n",
        "        self.n = initial_n\n",
        "        self.matrix = [[0] * self.n for _ in range(self.n)]\n",
        "\n",
        "    def increment(self, x=1):\n",
        "        self.n += x\n",
        "        # Add new columns to existing rows\n",
        "        for row in self.matrix:\n",
        "            row.extend([0] * x)\n",
        "        # Add new rows\n",
        "        for _ in range(x):\n",
        "            self.matrix.append([0] * self.n)\n",
        "\n",
        "    def set_value(self, row, col, value):\n",
        "        if 0 <= row < self.n and 0 <= col < self.n:\n",
        "            self.matrix[row][col] = value\n",
        "        else:\n",
        "            raise IndexError(\"Index out of bounds\")\n",
        "\n",
        "    def get_value(self, row, col):\n",
        "        if 0 <= row < self.n and 0 <= col < self.n:\n",
        "            return self.matrix[row][col]\n",
        "        raise IndexError(\"Index out of bounds\")\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row, col = idx\n",
        "        return self.get_value(row, col)\n",
        "\n",
        "    def __setitem__(self, idx, value):\n",
        "        row, col = idx\n",
        "        self.set_value(row, col, value)\n",
        "\n",
        "    def get_qubo(self):\n",
        "        return  np.array(self.matrix,dtype=np.float64)\n",
        "\n",
        "    def __str__(self):\n",
        "        return '\\n'.join(' '.join(str(x) for x in row) for row in self.matrix)\n",
        "\n",
        "def add_equality(Q:DynamicMatrix,V:list,I:list,C,Panelty=1000):\n",
        "    #sum V[i]*I[i] =C\n",
        "    for ii,i in enumerate(I):\n",
        "        for jj,j in enumerate(I):\n",
        "            if j==i:\n",
        "                Q[i,i]+=(V[ii]*V[ii]-2*V[ii]*C)*Panelty\n",
        "                continue\n",
        "            Q[i,j]+=V[ii]*V[jj]*Panelty\n",
        "\n",
        "def make_symetric(Q:DynamicMatrix):\n",
        "    for i in range(Q.n):\n",
        "        for j in range(i+1,Q.n):\n",
        "            Q[i,j]=Q[j,i]=(Q[i,j]+Q[j,i])/2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmrQbu5k_FTH"
      },
      "source": [
        "constraints.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "I3pSzv2Y-xip"
      },
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "from dataclasses import dataclass\n",
        "from typing import List, Optional, Sequence, Tuple\n",
        "import numpy as np\n",
        "\n",
        "class Constraint:\n",
        "    \"\"\"Base class for constraints.\"\"\"\n",
        "\n",
        "    def is_feasible(self, x: np.ndarray) -> bool:\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def violation(self, x: np.ndarray) -> float:\n",
        "        \"\"\"Nonnegative violation magnitude; 0 if feasible.\"\"\"\n",
        "        raise NotImplementedError\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class CardinalityConstraint(Constraint):\n",
        "    \"\"\"Enforce sum(x) == K.\"\"\"\n",
        "\n",
        "    K: int\n",
        "\n",
        "    def is_feasible(self, x: np.ndarray) -> bool:\n",
        "        return int(np.sum(x)) == int(self.K)\n",
        "\n",
        "    def violation(self, x: np.ndarray) -> float:\n",
        "        s = float(np.sum(x))\n",
        "        return (s - float(self.K)) ** 2\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class LinearInequalityConstraint(Constraint):\n",
        "    \"\"\"Enforce A x <= b (componentwise).\"\"\"\n",
        "\n",
        "    A: np.ndarray  # (m, d)\n",
        "    b: np.ndarray  # (m,)\n",
        "\n",
        "    def __post_init__(self):\n",
        "        self.A = np.asarray(self.A, dtype=np.float64)\n",
        "        self.b = np.asarray(self.b, dtype=np.float64)\n",
        "\n",
        "    def is_feasible(self, x: np.ndarray) -> bool:\n",
        "        Ax = self.A @ x.astype(np.float64)\n",
        "        return bool(np.all(Ax <= self.b + 1e-12))\n",
        "\n",
        "    def violation(self, x: np.ndarray) -> float:\n",
        "        Ax = self.A @ x.astype(np.float64)\n",
        "        v = np.maximum(0.0, Ax - self.b)**2\n",
        "        return float(np.sum(v))\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class CompositeConstraint(Constraint):\n",
        "    \"\"\"Logical AND of multiple constraints.\"\"\"\n",
        "\n",
        "    constraints: List[Constraint]\n",
        "\n",
        "    def is_feasible(self, x: np.ndarray) -> bool:\n",
        "        return all(c.is_feasible(x) for c in self.constraints)\n",
        "\n",
        "    def violation(self, x: np.ndarray) -> float:\n",
        "        return float(sum(c.violation(x) for c in self.constraints))\n",
        "\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class OneHotGroupsConstraint(Constraint):\n",
        "    \"\"\"Enforce one-hot in each group: for every G, sum_{i in G} x_i == 1.\"\"\"\n",
        "\n",
        "    groups: List[np.ndarray]  # each group is a 1D array of indices\n",
        "\n",
        "    def __post_init__(self):\n",
        "        norm_groups: List[np.ndarray] = []\n",
        "        for g in self.groups:\n",
        "            gi = np.asarray(g, dtype=np.int64).reshape(-1)\n",
        "            if gi.size == 0:\n",
        "                raise ValueError(\"OneHotGroupsConstraint: empty group is not allowed\")\n",
        "            norm_groups.append(gi)\n",
        "        self.groups = norm_groups\n",
        "\n",
        "    def is_feasible(self, x: np.ndarray) -> bool:\n",
        "        x = np.asarray(x, dtype=np.int8)\n",
        "        for g in self.groups:\n",
        "            if int(np.sum(x[g])) != 1:\n",
        "                return False\n",
        "        return True\n",
        "\n",
        "    def violation(self, x: np.ndarray) -> float:\n",
        "        x = np.asarray(x, dtype=np.int8)\n",
        "        v = 0.0\n",
        "        for g in self.groups:\n",
        "            s = float(np.sum(x[g]))\n",
        "            v += (s - 1.0) ** 2\n",
        "        return float(v)\n",
        "\n",
        "\n",
        "def batch_is_feasible(X: np.ndarray, cons: Optional[Constraint]) -> np.ndarray:\n",
        "    if cons is None:\n",
        "        return np.ones((len(X),), dtype=bool)\n",
        "    return np.array([cons.is_feasible(x) for x in X], dtype=bool)\n",
        "\n",
        "\n",
        "def batch_violation(X: np.ndarray, cons: Optional[Constraint]) -> np.ndarray:\n",
        "    if cons is None:\n",
        "        return np.zeros((len(X),), dtype=np.float64)\n",
        "    return np.array([cons.violation(x) for x in X], dtype=np.float64)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CqYHXnM4_Lz7"
      },
      "source": [
        "qubo.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "NaQqjIks_OdX"
      },
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "from typing import Tuple\n",
        "import numpy as np\n",
        "\n",
        "def qubo_energy(X: np.ndarray, Q: np.ndarray, const: float = 0.0) -> np.ndarray:\n",
        "    \"\"\"Compute y = const + sum_{i<=j} Q[i,j] x_i x_j for a batch X.\n",
        "\n",
        "    Assumes Q is upper-triangular (diagonal contains linear terms).\n",
        "    X: (B, d) with 0/1.\n",
        "    Returns (B,) float.\n",
        "    \"\"\"\n",
        "    if X.ndim != 2:\n",
        "        raise ValueError(\"X must be 2D\")\n",
        "    B, d = X.shape\n",
        "    if Q.shape != (d, d):\n",
        "        raise ValueError(\"Q shape mismatch\")\n",
        "\n",
        "    # Efficient: compute (X @ Q) elementwise times X, but must avoid double counting\n",
        "    # since Q is upper-triangular for i<=j exactly.\n",
        "    # We'll do explicit upper triangle multiplication for clarity in template.\n",
        "    y = np.full((B,), float(const), dtype=np.float64)\n",
        "    # diagonal\n",
        "    y += np.sum(X * np.diag(Q)[None, :], axis=1)\n",
        "    # off diagonal\n",
        "    iu = np.triu_indices(d, k=1)\n",
        "    if len(iu[0]) > 0:\n",
        "        y += np.sum((X[:, iu[0]] * X[:, iu[1]]) * Q[iu][None, :], axis=1)\n",
        "    return y\n",
        "\n",
        "\n",
        "def symmetrize_upper(Q_upper: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"Return a symmetric matrix equivalent to the upper-triangular QUBO.\"\"\"\n",
        "    Q = np.array(Q_upper, copy=True)\n",
        "    Q = Q + np.triu(Q, 1).T\n",
        "    return Q\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xz4_iBUQ_kpl"
      },
      "source": [
        "data.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "9NIiQuB9_oaz"
      },
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "from dataclasses import dataclass, field\n",
        "from typing import Dict, List, Optional, Tuple\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class DataBuffer:\n",
        "    \"\"\"Stores feasible (X,y) for regression and (X,label) for feasibility classification.\"\"\"\n",
        "\n",
        "    X_reg: List[np.ndarray] = field(default_factory=list)\n",
        "    y_reg: List[float] = field(default_factory=list)\n",
        "\n",
        "    X_clf: List[np.ndarray] = field(default_factory=list)\n",
        "    y_clf: List[int] = field(default_factory=list)  # 1 feasible, 0 infeasible\n",
        "\n",
        "    def add_reg(self, x: np.ndarray, y: float) -> None:\n",
        "        self.X_reg.append(np.asarray(x, dtype=np.int8))\n",
        "        self.y_reg.append(float(y))\n",
        "\n",
        "    def add_clf(self, x: np.ndarray, label: int) -> None:\n",
        "        self.X_clf.append(np.asarray(x, dtype=np.int8))\n",
        "        self.y_clf.append(int(label))\n",
        "\n",
        "    def add_point(self, x: np.ndarray, feasible: bool, y: Optional[float] = None) -> None:\n",
        "        self.add_clf(x, 1 if feasible else 0)\n",
        "        if feasible:\n",
        "            if y is None:\n",
        "                raise ValueError(\"Feasible point requires y\")\n",
        "            self.add_reg(x, float(y))\n",
        "\n",
        "    def get_reg_arrays(self) -> Tuple[np.ndarray, np.ndarray]:\n",
        "        if not self.X_reg:\n",
        "            return np.zeros((0, 0), dtype=np.int8), np.zeros((0,), dtype=float)\n",
        "        X = np.stack(self.X_reg, axis=0)\n",
        "        y = np.asarray(self.y_reg, dtype=float)\n",
        "        return X, y\n",
        "\n",
        "    def get_clf_arrays(self) -> Tuple[np.ndarray, np.ndarray]:\n",
        "        if not self.X_clf:\n",
        "            return np.zeros((0, 0), dtype=np.int8), np.zeros((0,), dtype=np.int64)\n",
        "        X = np.stack(self.X_clf, axis=0)\n",
        "        y = np.asarray(self.y_clf, dtype=np.int64)\n",
        "        return X, y\n",
        "\n",
        "    def size_reg(self) -> int:\n",
        "        return len(self.y_reg)\n",
        "\n",
        "    def size_clf(self) -> int:\n",
        "        return len(self.y_clf)\n",
        "\n",
        "    def summary(self) -> Dict[str, int]:\n",
        "        return {\"n_reg\": self.size_reg(), \"n_clf\": self.size_clf()}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8DWE8ARD_weT"
      },
      "source": [
        "fm.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "qgMhLY_8_zxK"
      },
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "from dataclasses import dataclass\n",
        "from typing import Dict, Optional, Tuple\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "\n",
        "class FactorizationMachine(nn.Module):\n",
        "    \"\"\"Second-order Factorization Machine for binary/categorical (one-hot) features.\n",
        "\n",
        "    Prediction:\n",
        "        y = w0 + sum_i w_i x_i + sum_{i<j} <v_i, v_j> x_i x_j\n",
        "\n",
        "    This is naturally a QUBO when x is binary.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, d: int, k: int):\n",
        "        super().__init__()\n",
        "        self.d = int(d)\n",
        "        self.k = int(k)\n",
        "\n",
        "        self.w0 = nn.Parameter(torch.zeros(1))\n",
        "        self.w = nn.Parameter(torch.zeros(d))\n",
        "        self.V = nn.Parameter(torch.randn(d, k) * 0.01)\n",
        "\n",
        "        # Optional output scaling for regression:\n",
        "        self.y_mean = 0.0\n",
        "        self.y_std = 1.0\n",
        "\n",
        "    def forward(self, X: torch.Tensor) -> torch.Tensor:\n",
        "        # X: (B, d), float32\n",
        "        linear = self.w0 + X @ self.w\n",
        "        # FM trick:\n",
        "        XV = X @ self.V                # (B, k)\n",
        "        XV2 = XV * XV                  # (B, k)\n",
        "        X2V2 = (X * X) @ (self.V * self.V)  # (B, k)\n",
        "        interactions = 0.5 * torch.sum(XV2 - X2V2, dim=1)  # (B,)\n",
        "        return linear + interactions\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class FMTrainConfig:\n",
        "    k: int = 16\n",
        "    lr: float = 2e-2\n",
        "    weight_decay: float = 1e-4\n",
        "    epochs: int = 200\n",
        "    batch_size: int = 256\n",
        "    patience: int = 20\n",
        "    device: str = \"cpu\"\n",
        "\n",
        "\n",
        "def _batch_iter(X: np.ndarray, y: np.ndarray, batch_size: int, rng: np.random.Generator):\n",
        "    n = len(X)\n",
        "    idx = np.arange(n)\n",
        "    rng.shuffle(idx)\n",
        "    for s in range(0, n, batch_size):\n",
        "        j = idx[s : s + batch_size]\n",
        "        yield X[j], y[j]\n",
        "\n",
        "\n",
        "def train_fm_regression(\n",
        "    X: np.ndarray,\n",
        "    y: np.ndarray,\n",
        "    cfg: FMTrainConfig,\n",
        "    seed: int = 0,\n",
        ") -> Tuple[FactorizationMachine, Dict[str, float]]:\n",
        "    \"\"\"Train FM with MSE loss. Returns trained model and final losses.\"\"\"\n",
        "    if X.ndim != 2:\n",
        "        raise ValueError(\"X must be 2D\")\n",
        "    if len(X) != len(y):\n",
        "        raise ValueError(\"X and y length mismatch\")\n",
        "    if len(X) < 2:\n",
        "        raise ValueError(\"Need at least 2 training points for regression\")\n",
        "\n",
        "    rng = np.random.default_rng(seed)\n",
        "\n",
        "    d = X.shape[1]\n",
        "    model = FactorizationMachine(d=d, k=cfg.k)\n",
        "    device = torch.device(cfg.device)\n",
        "    model.to(device)\n",
        "\n",
        "    # Standardize targets for stability:\n",
        "    y_mean = float(np.mean(y))\n",
        "    y_std = float(np.std(y) + 1e-8)\n",
        "    model.y_mean = y_mean\n",
        "    model.y_std = y_std\n",
        "    y_s = (y - y_mean) / y_std\n",
        "\n",
        "    X_t = torch.tensor(X, dtype=torch.float32, device=device)\n",
        "    y_t = torch.tensor(y_s, dtype=torch.float32, device=device)\n",
        "\n",
        "    opt = torch.optim.Adam(model.parameters(), lr=cfg.lr, weight_decay=cfg.weight_decay)\n",
        "    loss_fn = nn.MSELoss()\n",
        "\n",
        "    best_loss = float(\"inf\")\n",
        "    best_state = None\n",
        "    bad = 0\n",
        "\n",
        "    for epoch in range(cfg.epochs):\n",
        "        model.train()\n",
        "        epoch_loss = 0.0\n",
        "        for xb, yb in _batch_iter(X, y_s, cfg.batch_size, rng):\n",
        "            xb_t = torch.tensor(xb, dtype=torch.float32, device=device)\n",
        "            yb_t = torch.tensor(yb, dtype=torch.float32, device=device)\n",
        "\n",
        "            opt.zero_grad(set_to_none=True)\n",
        "            pred = model(xb_t)\n",
        "            loss = loss_fn(pred, yb_t)\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "\n",
        "            epoch_loss += float(loss.item()) * len(xb)\n",
        "\n",
        "        epoch_loss /= len(X)\n",
        "\n",
        "        # Simple early stopping on training loss (template-friendly)\n",
        "        if epoch_loss < best_loss - 1e-6:\n",
        "            best_loss = epoch_loss\n",
        "            best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
        "            bad = 0\n",
        "        else:\n",
        "            bad += 1\n",
        "            if bad >= cfg.patience:\n",
        "                break\n",
        "\n",
        "    if best_state is not None:\n",
        "        model.load_state_dict(best_state)\n",
        "\n",
        "    return model, {\"train_mse\": best_loss}\n",
        "\n",
        "\n",
        "def train_fm_classifier(\n",
        "    X: np.ndarray,\n",
        "    y01: np.ndarray,\n",
        "    cfg: FMTrainConfig,\n",
        "    seed: int = 0,\n",
        ") -> Tuple[FactorizationMachine, Dict[str, float]]:\n",
        "    \"\"\"Train FM as a binary classifier with BCEWithLogits loss.\"\"\"\n",
        "    if X.ndim != 2:\n",
        "        raise ValueError(\"X must be 2D\")\n",
        "    if len(X) != len(y01):\n",
        "        raise ValueError(\"X and y length mismatch\")\n",
        "    if len(X) < 10:\n",
        "        raise ValueError(\"Need at least 10 points for classifier (template default)\")\n",
        "\n",
        "    rng = np.random.default_rng(seed)\n",
        "\n",
        "    d = X.shape[1]\n",
        "    model = FactorizationMachine(d=d, k=cfg.k)\n",
        "    device = torch.device(cfg.device)\n",
        "    model.to(device)\n",
        "\n",
        "    X_t = torch.tensor(X, dtype=torch.float32, device=device)\n",
        "    y_t = torch.tensor(y01.astype(np.float32), dtype=torch.float32, device=device)\n",
        "\n",
        "    opt = torch.optim.Adam(model.parameters(), lr=cfg.lr, weight_decay=cfg.weight_decay)\n",
        "    loss_fn = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    best_loss = float(\"inf\")\n",
        "    best_state = None\n",
        "    bad = 0\n",
        "\n",
        "    for epoch in range(cfg.epochs):\n",
        "        model.train()\n",
        "        epoch_loss = 0.0\n",
        "        for xb, yb in _batch_iter(X, y01.astype(np.float32), cfg.batch_size, rng):\n",
        "            xb_t = torch.tensor(xb, dtype=torch.float32, device=device)\n",
        "            yb_t = torch.tensor(yb, dtype=torch.float32, device=device)\n",
        "\n",
        "            opt.zero_grad(set_to_none=True)\n",
        "            logits = model(xb_t)\n",
        "            loss = loss_fn(logits, yb_t)\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "\n",
        "            epoch_loss += float(loss.item()) * len(xb)\n",
        "\n",
        "        epoch_loss /= len(X)\n",
        "\n",
        "        if epoch_loss < best_loss - 1e-6:\n",
        "            best_loss = epoch_loss\n",
        "            best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
        "            bad = 0\n",
        "        else:\n",
        "            bad += 1\n",
        "            if bad >= cfg.patience:\n",
        "                break\n",
        "\n",
        "    if best_state is not None:\n",
        "        model.load_state_dict(best_state)\n",
        "\n",
        "    return model, {\"train_bce\": best_loss}\n",
        "\n",
        "\n",
        "def fm_predict_reg(model: FactorizationMachine, X: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"Predict regression output in the original y scale.\"\"\"\n",
        "    device = next(model.parameters()).device\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        xt = torch.tensor(X, dtype=torch.float32, device=device)\n",
        "        y_s = model(xt).detach().cpu().numpy()\n",
        "    return model.y_mean + model.y_std * y_s\n",
        "\n",
        "\n",
        "def fm_predict_proba(model: FactorizationMachine, X: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"Predict feasibility probability (sigmoid of logits).\"\"\"\n",
        "    device = next(model.parameters()).device\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        xt = torch.tensor(X, dtype=torch.float32, device=device)\n",
        "        logits = model(xt).detach().cpu().numpy()\n",
        "    return 1.0 / (1.0 + np.exp(-logits))\n",
        "\n",
        "\n",
        "def fm_to_qubo(model: FactorizationMachine) -> Tuple[np.ndarray, float]:\n",
        "    \"\"\"Convert a trained FM (regression) into an upper-triangular QUBO and constant.\n",
        "\n",
        "    We output Q such that:\n",
        "        y_hat(x) = const + sum_{i<=j} Q[i,j] x_i x_j\n",
        "    for x in {0,1}^d.\n",
        "\n",
        "    Note: linear terms are placed on the diagonal because x_i^2 = x_i for binary x.\n",
        "    \"\"\"\n",
        "    w0 = float(model.w0.detach().cpu().numpy().reshape(()))\n",
        "    w = model.w.detach().cpu().numpy().astype(np.float64)\n",
        "    V = model.V.detach().cpu().numpy().astype(np.float64)\n",
        "\n",
        "    d = len(w)\n",
        "    Q = np.zeros((d, d), dtype=np.float64)\n",
        "\n",
        "    # diagonal = linear terms\n",
        "    Q[np.arange(d), np.arange(d)] = w\n",
        "\n",
        "    # off-diagonal = dot(v_i, v_j)\n",
        "    G = V @ V.T  # (d, d), where G[i,j] = <v_i, v_j>\n",
        "    for i in range(d):\n",
        "        for j in range(i + 1, d):\n",
        "            Q[i, j] = G[i, j]\n",
        "\n",
        "    # undo y standardization: y = mean + std * y_std\n",
        "    const = model.y_mean + model.y_std * w0\n",
        "    Q = model.y_std * Q\n",
        "\n",
        "    return Q, float(const)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7988HdSc_0vO"
      },
      "source": [
        "utils.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "Ymo9Mv_gAClh"
      },
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "import json\n",
        "import os\n",
        "import random\n",
        "from dataclasses import dataclass\n",
        "from pathlib import Path\n",
        "from typing import Any, Dict, Iterable, List, Optional, Sequence, Tuple\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def set_global_seed(seed: int) -> None:\n",
        "    \"\"\"Seed Python + NumPy (and optionally Torch) for reproducibility.\"\"\"\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    try:\n",
        "        import torch\n",
        "\n",
        "        torch.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "\n",
        "def ensure_dir(path: str | Path) -> Path:\n",
        "    p = Path(path)\n",
        "    p.mkdir(parents=True, exist_ok=True)\n",
        "    return p\n",
        "\n",
        "\n",
        "def save_json(path: str | Path, obj: Any) -> None:\n",
        "    Path(path).write_text(json.dumps(obj, indent=2, sort_keys=True), encoding=\"utf-8\")\n",
        "\n",
        "\n",
        "def load_json(path: str | Path) -> Any:\n",
        "    return json.loads(Path(path).read_text(encoding=\"utf-8\"))\n",
        "\n",
        "\n",
        "def unique_rows(X: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"Return unique rows of a 2D numpy array (preserving order).\"\"\"\n",
        "    if X.ndim != 2:\n",
        "        raise ValueError(\"X must be 2D\")\n",
        "    seen = set()\n",
        "    out = []\n",
        "    for row in X:\n",
        "        key = row.tobytes()\n",
        "        if key not in seen:\n",
        "            seen.add(key)\n",
        "            out.append(row)\n",
        "    return np.array(out, dtype=X.dtype)\n",
        "\n",
        "\n",
        "def hamming_distance(a: np.ndarray, b: np.ndarray) -> int:\n",
        "    return int(np.sum(a != b))\n",
        "\n",
        "\n",
        "def topk_unique(\n",
        "    X: np.ndarray,\n",
        "    y: np.ndarray,\n",
        "    k: int,\n",
        ") -> Tuple[np.ndarray, np.ndarray]:\n",
        "    \"\"\"Pick top-k (smallest y), ensure unique rows.\"\"\"\n",
        "    if len(X) == 0:\n",
        "        return X, y\n",
        "    order = np.argsort(y)\n",
        "    Xs = X[order]\n",
        "    ys = y[order]\n",
        "    picked = []\n",
        "    picked_y = []\n",
        "    seen = set()\n",
        "    for xi, yi in zip(Xs, ys):\n",
        "        key = xi.tobytes()\n",
        "        if key in seen:\n",
        "            continue\n",
        "        seen.add(key)\n",
        "        picked.append(xi)\n",
        "        picked_y.append(float(yi))\n",
        "        if len(picked) >= k:\n",
        "            break\n",
        "    return np.array(picked, dtype=X.dtype), np.array(picked_y, dtype=float)\n",
        "\n",
        "\n",
        "def _rankdata_average_ties(x: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"Ranks with average rank for ties (1..n).\"\"\"\n",
        "    x = np.asarray(x)\n",
        "    order = np.argsort(x, kind=\"mergesort\")\n",
        "    ranks = np.empty_like(order, dtype=np.float64)\n",
        "\n",
        "    xs = x[order]\n",
        "    n = len(xs)\n",
        "    i = 0\n",
        "    while i < n:\n",
        "        j = i + 1\n",
        "        while j < n and xs[j] == xs[i]:\n",
        "            j += 1\n",
        "        # average rank for [i, j)\n",
        "        r = 0.5 * ((i + 1) + j)  # 1-indexed\n",
        "        ranks[order[i:j]] = r\n",
        "        i = j\n",
        "    return ranks\n",
        "\n",
        "\n",
        "def spearmanr_np(a: np.ndarray, b: np.ndarray) -> float:\n",
        "    \"\"\"Spearman rank correlation (robust to ties via average ranks).\"\"\"\n",
        "    a = np.asarray(a, dtype=np.float64).reshape(-1)\n",
        "    b = np.asarray(b, dtype=np.float64).reshape(-1)\n",
        "    if a.size != b.size:\n",
        "        raise ValueError(\"spearmanr_np: size mismatch\")\n",
        "    if a.size < 2:\n",
        "        return float(\"nan\")\n",
        "\n",
        "    ra = _rankdata_average_ties(a)\n",
        "    rb = _rankdata_average_ties(b)\n",
        "    ra = ra - np.mean(ra)\n",
        "    rb = rb - np.mean(rb)\n",
        "\n",
        "    denom = float(np.sqrt(np.sum(ra * ra) * np.sum(rb * rb)) + 1e-12)\n",
        "    return float(np.sum(ra * rb) / denom)\n",
        "\n",
        "\n",
        "def select_diverse_topk(\n",
        "    X: np.ndarray,\n",
        "    y: np.ndarray,\n",
        "    k: int,\n",
        "    min_hamming: int = 0,\n",
        ") -> Tuple[np.ndarray, np.ndarray]:\n",
        "    \"\"\"Pick up to k smallest-y rows, enforcing min Hamming distance greedily.\"\"\"\n",
        "    if len(X) == 0 or k <= 0:\n",
        "        return np.zeros((0, X.shape[1] if X.ndim == 2 else 0), dtype=getattr(X, \"dtype\", np.int8)), np.zeros((0,), dtype=float)\n",
        "\n",
        "    X = np.asarray(X)\n",
        "    y = np.asarray(y, dtype=np.float64)\n",
        "    order = np.argsort(y)\n",
        "    Xs = X[order]\n",
        "    ys = y[order]\n",
        "\n",
        "    picked_X: List[np.ndarray] = []\n",
        "    picked_y: List[float] = []\n",
        "\n",
        "    for xi, yi in zip(Xs, ys):\n",
        "        if not picked_X:\n",
        "            picked_X.append(xi)\n",
        "            picked_y.append(float(yi))\n",
        "        else:\n",
        "            if min_hamming > 0:\n",
        "                ok = True\n",
        "                for xj in picked_X:\n",
        "                    if hamming_distance(xi, xj) < min_hamming:\n",
        "                        ok = False\n",
        "                        break\n",
        "                if not ok:\n",
        "                    continue\n",
        "            picked_X.append(xi)\n",
        "            picked_y.append(float(yi))\n",
        "\n",
        "        if len(picked_X) >= k:\n",
        "            break\n",
        "\n",
        "    return np.array(picked_X, dtype=X.dtype), np.array(picked_y, dtype=np.float64)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRoW0LShAGEC"
      },
      "source": [
        "surrogate.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "rdQkDamRAUdB"
      },
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "from dataclasses import dataclass\n",
        "from typing import Optional\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "#from .constraints import Constraint, batch_violation\n",
        "#from .qubo import qubo_energy\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class SurrogateObjective:\n",
        "    \"\"\"Surrogate energy used by the solver.\n",
        "\n",
        "    E(x) = QUBO(x) + rho * violation(x) - alpha * log(p_feasible(x)+eps)\n",
        "\n",
        "    All terms are optional except QUBO.\n",
        "    \"\"\"\n",
        "\n",
        "    Q: np.ndarray\n",
        "    const: float\n",
        "    constraint: Optional[Constraint] = None\n",
        "    rho: float = 0.0\n",
        "    p_feasible: Optional[callable] = None  # function X -> prob in (0,1)\n",
        "    alpha: float = 0.0\n",
        "    eps: float = 1e-6\n",
        "\n",
        "    def __call__(self, X: np.ndarray) -> np.ndarray:\n",
        "        X = np.asarray(X, dtype=np.int8)\n",
        "        e = qubo_energy(X, self.Q, self.const)\n",
        "\n",
        "        if self.constraint is not None and self.rho != 0.0:\n",
        "            v = batch_violation(X, self.constraint)\n",
        "            e = e + float(self.rho) * v\n",
        "\n",
        "        if self.p_feasible is not None and self.alpha != 0.0:\n",
        "            p = np.clip(self.p_feasible(X), self.eps, 1.0 - self.eps)\n",
        "            e = e - float(self.alpha) * np.log(p)\n",
        "\n",
        "        return e.astype(np.float64)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmD2u7N97BTv"
      },
      "source": [
        "Benchmarks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "B19dfCwt7mDS"
      },
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "from dataclasses import dataclass\n",
        "from typing import Dict, Optional, Tuple\n",
        "\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "BH4nPwoo7AlC"
      },
      "outputs": [],
      "source": [
        "class Benchmark:\n",
        "    \"\"\"A black-box objective with constraints over binary x.\"\"\"\n",
        "\n",
        "    name: str\n",
        "\n",
        "    def n_vars(self) -> int:\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def constraint(self) -> Optional[Constraint]:\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def oracle(self, x: np.ndarray) -> float:\n",
        "        \"\"\"Objective to minimize. Only meaningful on feasible points.\"\"\"\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def sample_feasible(self, rng: np.random.Generator, n: int) -> np.ndarray:\n",
        "        \"\"\"Return (n, d) feasible samples.\"\"\"\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def info(self) -> Dict:\n",
        "        return {\"name\": getattr(self, \"name\", self.__class__.__name__), \"d\": self.n_vars()}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ma86FJEAiEw"
      },
      "source": [
        "knapsack.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "_3SFqVd37rx0"
      },
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "from dataclasses import dataclass\n",
        "from typing import Dict, Optional, Tuple\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "#from ..constraints import Constraint, LinearInequalityConstraint\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class KnapsackBenchmark:\n",
        "    \"\"\"0-1 knapsack (minimization version).\n",
        "\n",
        "    Items i=1..d with weights w_i and values v_i.\n",
        "    Constraint: sum w_i x_i <= capacity.\n",
        "    Objective (minimize): - sum v_i x_i  (i.e., maximize value)\n",
        "    \"\"\"\n",
        "\n",
        "    d: int\n",
        "    seed: int = 0\n",
        "    capacity_ratio: float = 0.35\n",
        "\n",
        "    def __post_init__(self):\n",
        "        rng = np.random.default_rng(self.seed)\n",
        "        self.weights = rng.integers(low=1, high=50, size=self.d).astype(np.float64)\n",
        "        self.values = rng.integers(low=1, high=100, size=self.d).astype(np.float64)\n",
        "        self.capacity = float(np.sum(self.weights) * self.capacity_ratio)\n",
        "        self.name = f\"knapsack_d{self.d}_seed{self.seed}_cap{self.capacity_ratio:.2f}\"\n",
        "\n",
        "    def n_vars(self) -> int:\n",
        "        return self.d\n",
        "\n",
        "    def constraint(self) -> Optional[Constraint]:\n",
        "        A = self.weights.reshape(1, -1)\n",
        "        b = np.array([self.capacity], dtype=np.float64)\n",
        "        return LinearInequalityConstraint(A=A, b=b)\n",
        "\n",
        "    def oracle(self, x: np.ndarray) -> float:\n",
        "        return -float(np.dot(self.values, x.astype(np.float64)))\n",
        "\n",
        "    def sample_feasible(self, rng: np.random.Generator, n: int) -> np.ndarray:\n",
        "        # Simple greedy+random feasible generator\n",
        "        X = np.zeros((n, self.d), dtype=np.int8)\n",
        "        for t in range(n):\n",
        "            idx = rng.permutation(self.d)\n",
        "            wsum = 0.0\n",
        "            x = np.zeros(self.d, dtype=np.int8)\n",
        "            for i in idx:\n",
        "                if wsum + self.weights[i] <= self.capacity and rng.random() < 0.5:\n",
        "                    x[i] = 1\n",
        "                    wsum += self.weights[i]\n",
        "            X[t] = x\n",
        "        return X\n",
        "\n",
        "    def print_results(self,x):\n",
        "        W,V=0,0\n",
        "        for i in range(self.d):\n",
        "            W+=x[i]*self.weights[i]\n",
        "            V+=x[i]*self.values[i]\n",
        "        print('capacity:',self.capacity,'Weight:',W,'Value:',V)\n",
        "\n",
        "    def get_capacity(self):\n",
        "        return self.capacity\n",
        "\n",
        "    def info(self) -> Dict:\n",
        "        return {\"name\": self.name, \"d\": self.d, \"seed\": self.seed, \"capacity\": self.capacity, \"capacity_ratio\": self.capacity_ratio}\n",
        "\n",
        "def get_knapsack_qubo(P:KnapsackBenchmark):\n",
        "    n,Weight,Value,capacity=P.d,P.weights,P.values,P.capacity\n",
        "    Q=DynamicMatrix(n)\n",
        "    #add objective function\n",
        "    for i in range(n):\n",
        "        Q[i,i]-=Value[i]\n",
        "    #Constraint: sum w_i x_i <= capacity.\n",
        "    b=int(np.log2(capacity+1)+1)\n",
        "    Q.increment(b)\n",
        "    #(sum w_i x_i +b_i*2**i-capacity)**2\n",
        "    add_equality(Q,[Weight[i] for i in range(n)]+[2**i for i in range(b)],[i for i in range(Q.n)],capacity)\n",
        "    return Q.get_qubo()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCQZlEU2AqFE"
      },
      "source": [
        "maxcut_cardinality.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "DGqBUX9SAtld"
      },
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "from dataclasses import dataclass\n",
        "from itertools import combinations\n",
        "from typing import Dict, Optional, Tuple\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "#from ..constraints import CardinalityConstraint, Constraint\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class MaxCutCardinalityBenchmark:\n",
        "    \"\"\"Constrained MaxCut variant: choose exactly K vertices in a subset S.\n",
        "\n",
        "    Decision x in {0,1}^d indicates membership in S.\n",
        "    Constraint: sum(x) == K.\n",
        "\n",
        "    Objective (minimize): negative cut weight\n",
        "        f(x) = - sum_{i<j} w_ij * [x_i != x_j]\n",
        "    \"\"\"\n",
        "\n",
        "    d: int\n",
        "    K: int\n",
        "    seed: int = 0\n",
        "    weight_scale: float = 1.0\n",
        "\n",
        "    def __post_init__(self):\n",
        "        rng = np.random.default_rng(self.seed)\n",
        "        W = rng.random((self.d, self.d)) * self.weight_scale\n",
        "        W = np.triu(W, 1)\n",
        "        W = W + W.T\n",
        "        np.fill_diagonal(W, 0.0)\n",
        "        self.W = W\n",
        "        self.name = f\"maxcut_cardinality_d{self.d}_K{self.K}_seed{self.seed}\"\n",
        "\n",
        "    def n_vars(self) -> int:\n",
        "        return self.d\n",
        "\n",
        "    def constraint(self) -> Optional[Constraint]:\n",
        "        return CardinalityConstraint(K=self.K)\n",
        "\n",
        "    def cut_weight(self, x: np.ndarray) -> float:\n",
        "        x = x.astype(np.int8)\n",
        "        # Compute sum_{i<j} w_ij * (x_i xor x_j)\n",
        "        # xor = x_i + x_j - 2 x_i x_j for binary\n",
        "        # Use vectorized formula:\n",
        "        # For upper triangle: sum w_ij * (x_i + x_j - 2 x_i x_j)\n",
        "        iu = np.triu_indices(self.d, 1)\n",
        "        xi = x[iu[0]].astype(np.float64)\n",
        "        xj = x[iu[1]].astype(np.float64)\n",
        "        xor = xi + xj - 2.0 * xi * xj\n",
        "        return float(np.sum(self.W[iu] * xor))\n",
        "\n",
        "    def oracle(self, x: np.ndarray) -> float:\n",
        "        # minimize negative cut weight (maximize cut)\n",
        "        return -self.cut_weight(x)\n",
        "\n",
        "    def sample_feasible(self, rng: np.random.Generator, n: int) -> np.ndarray:\n",
        "        X = np.zeros((n, self.d), dtype=np.int8)\n",
        "        for i in range(n):\n",
        "            idx = rng.choice(self.d, size=self.K, replace=False)\n",
        "            X[i, idx] = 1\n",
        "        return X\n",
        "\n",
        "    def info(self) -> Dict:\n",
        "        return {\"name\": self.name, \"d\": self.d, \"K\": self.K, \"seed\": self.seed, \"weight_scale\": self.weight_scale}\n",
        "    def print_results(self,x):\n",
        "        W=0\n",
        "        cnt=0\n",
        "        for i in range(self.d):\n",
        "            cnt+=x[i]\n",
        "            for j in range(i+1,self.d):\n",
        "                if x[i]==x[j]:\n",
        "                    continue\n",
        "                W+=self.W[i][j]\n",
        "        print('Weight:',W,'Vertices Count:',cnt)\n",
        "    def brute_force_optimum(self, max_d: int = 24) -> Optional[Tuple[np.ndarray, float]]:\n",
        "        \"\"\"Compute exact optimum by enumerating all C(d,K) subsets if small.\"\"\"\n",
        "        if self.d > max_d:\n",
        "            return None\n",
        "        best_x = None\n",
        "        best_y = float(\"inf\")\n",
        "        for comb in combinations(range(self.d), self.K):\n",
        "            x = np.zeros(self.d, dtype=np.int8)\n",
        "            x[list(comb)] = 1\n",
        "            y = self.oracle(x)\n",
        "            if y < best_y:\n",
        "                best_y = y\n",
        "                best_x = x\n",
        "        if best_x is None:\n",
        "            return None\n",
        "        return best_x, float(best_y)\n",
        "\n",
        "def get_maxcut_qubo(P:MaxCutCardinalityBenchmark):\n",
        "    n=P.d\n",
        "    W=P.W\n",
        "    K=P.K\n",
        "    Q=DynamicMatrix(n)\n",
        "    for i in range(n):\n",
        "        for j in range(i+1,n):\n",
        "            W[i][j]=1\n",
        "            #-(x(i)*(1-x(j))+x(j)*(1-x(i)))*W[i][j]\n",
        "            Q[i,j]+=2*W[i][j]\n",
        "            Q[i,i]-=W[i][j]\n",
        "            Q[j,j]-=W[i][j]\n",
        "    add_equality(Q,np.ones(n),[i for i in range(n)],K)\n",
        "    make_symetric(Q)\n",
        "    return Q.get_qubo()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQ0PIEp3AvAU"
      },
      "source": [
        "onehot_qubo.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "JDgRH3eDAxDR"
      },
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "from dataclasses import dataclass\n",
        "from typing import Dict, List, Optional, Sequence\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "#from ..constraints import Constraint, OneHotGroupsConstraint\n",
        "#from ..qubo import qubo_energy\n",
        "\n",
        "\n",
        "def _build_groups(group_sizes: Sequence[int]) -> List[np.ndarray]:\n",
        "    groups: List[np.ndarray] = []\n",
        "    off = 0\n",
        "    for s in group_sizes:\n",
        "        s = int(s)\n",
        "        if s <= 0:\n",
        "            raise ValueError(\"group_sizes must be positive\")\n",
        "        groups.append(np.arange(off, off + s, dtype=np.int64))\n",
        "        off += s\n",
        "    return groups\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class OneHotQUBOBenchmark:\n",
        "    \"\"\"Synthetic constrained QUBO with one-hot groups.\n",
        "\n",
        "    Variables are partitioned into groups G1..Gm, constraint is sum_{i in Gk} x_i == 1.\n",
        "\n",
        "    Oracle (minimize): random QUBO energy. Optionally \"plant\" a feasible solution by\n",
        "    adding linear biases favoring one chosen index per group.\n",
        "    \"\"\"\n",
        "\n",
        "    group_sizes: Sequence[int]\n",
        "    seed: int = 0\n",
        "    interaction_scale: float = 1.0\n",
        "    planted_bias: float = 2.0  # >0 encourages planted indices (via negative linear terms)\n",
        "\n",
        "    def __post_init__(self):\n",
        "        self.groups = _build_groups(self.group_sizes)\n",
        "        self.d = int(sum(int(s) for s in self.group_sizes))\n",
        "\n",
        "        rng = np.random.default_rng(self.seed)\n",
        "\n",
        "        # random upper-triangular Q (diagonal = linear, off-diagonal = pairwise)\n",
        "        Q = rng.normal(loc=0.0, scale=float(self.interaction_scale), size=(self.d, self.d)).astype(np.float64)\n",
        "        Q = np.triu(Q, 0)\n",
        "\n",
        "        # optional planted feasible x*: pick one index per group and bias it lower\n",
        "        x_star = np.zeros((self.d,), dtype=np.int8)\n",
        "        for g in self.groups:\n",
        "            j = int(rng.choice(g))\n",
        "            x_star[j] = 1\n",
        "            Q[j, j] += -abs(float(self.planted_bias))  # lower energy when x_j=1\n",
        "\n",
        "        self.Q = Q\n",
        "        self.const = 0.0\n",
        "        self.x_star = x_star\n",
        "        self.name = f\"onehot_qubo_groups{len(self.groups)}_d{self.d}_seed{self.seed}\"\n",
        "\n",
        "    def n_vars(self) -> int:\n",
        "        return self.d\n",
        "\n",
        "    def constraint(self) -> Optional[Constraint]:\n",
        "        return OneHotGroupsConstraint(groups=self.groups)\n",
        "\n",
        "    def oracle(self, x: np.ndarray) -> float:\n",
        "        x = np.asarray(x, dtype=np.int8).reshape(1, -1)\n",
        "        return float(qubo_energy(x, self.Q, self.const)[0])\n",
        "\n",
        "    def sample_feasible(self, rng: np.random.Generator, n: int) -> np.ndarray:\n",
        "        X = np.zeros((int(n), self.d), dtype=np.int8)\n",
        "        for t in range(int(n)):\n",
        "            for g in self.groups:\n",
        "                j = int(rng.choice(g))\n",
        "                X[t, j] = 1\n",
        "        return X\n",
        "\n",
        "    def info(self) -> Dict:\n",
        "        return {\n",
        "            \"name\": self.name,\n",
        "            \"d\": self.d,\n",
        "            \"seed\": self.seed,\n",
        "            \"group_sizes\": [int(s) for s in self.group_sizes],\n",
        "            \"interaction_scale\": float(self.interaction_scale),\n",
        "            \"planted_bias\": float(self.planted_bias),\n",
        "        }\n",
        "    def print_results(self,x):\n",
        "        cnt=0\n",
        "        for g in self.groups:\n",
        "            s=0\n",
        "            for i in g:\n",
        "                s+=x[int(i)]\n",
        "            if(s!=1):\n",
        "                cnt+=1\n",
        "        print('violated:',cnt,'/',len(self.groups))\n",
        "def get_onehot_qubo(P:OneHotQUBOBenchmark):\n",
        "    groups=P.groups\n",
        "    n=P.d\n",
        "    Q=DynamicMatrix(n)\n",
        "\n",
        "    for g in groups:\n",
        "        add_equality(Q,np.ones(len(g)),g,1)\n",
        "    return Q.get_qubo()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbFu5Hxqifxd"
      },
      "source": [
        "portfolio.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "r3UsUxGGiiF7"
      },
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "from dataclasses import dataclass\n",
        "from typing import Dict, Optional\n",
        "import numpy as np\n",
        "\n",
        "#from constraints import Constraint, CardinalityConstraint\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class PortfolioBenchmark:\n",
        "    \"\"\"Portfolio optimization: Select K assets maximizing return, minimizing risk with diversification.\"\"\"\n",
        "\n",
        "    d: int = 50\n",
        "    K: int = 10\n",
        "    seed: int = 0\n",
        "    return_scale: float = 0.1\n",
        "    risk_scale: float = 0.3\n",
        "    diversity_weight: float = 0.1\n",
        "    risk_weight: float = 5.0\n",
        "\n",
        "    def __post_init__(self):\n",
        "        rng = np.random.default_rng(self.seed)\n",
        "\n",
        "        self.returns = rng.normal(loc=0.05, scale=self.return_scale, size=self.d)\n",
        "\n",
        "        self.risks = rng.uniform(low=0.1, high=self.risk_scale, size=self.d)\n",
        "\n",
        "        self.correlation = self._generate_correlation_matrix(rng, self.d)\n",
        "        self.covariance = np.outer(self.risks, self.risks) * self.correlation\n",
        "\n",
        "        self.name = f\"portfolio_d{self.d}_K{self.K}_seed{self.seed}\"\n",
        "\n",
        "    def _generate_correlation_matrix(self, rng: np.random.Generator, size: int) -> np.ndarray:\n",
        "\n",
        "        correlation = rng.uniform(low=-1, high=1, size=(size, size))\n",
        "        correlation = (correlation + correlation.T) / 2\n",
        "        np.fill_diagonal(correlation, 1.0)\n",
        "\n",
        "        return correlation\n",
        "\n",
        "    def n_vars(self) -> int:\n",
        "        return self.d\n",
        "\n",
        "    def constraint(self) -> Optional[Constraint]:\n",
        "        return CardinalityConstraint(K=self.K)\n",
        "\n",
        "    def portfolio_return(self, x: np.ndarray) -> float:\n",
        "        return float(np.dot(self.returns, x.astype(np.float64)))\n",
        "\n",
        "    def portfolio_risk(self, x: np.ndarray) -> float:\n",
        "        x_float = x.astype(np.float64)\n",
        "        return float(x_float.T @ self.covariance @ x_float)\n",
        "\n",
        "    def portfolio_diversification(self, x: np.ndarray) -> float:\n",
        "        n_selected = np.sum(x)\n",
        "        if n_selected <= 1:\n",
        "            return 0.0\n",
        "        #simple 1-1/n rule as we are putting same amount of money in each asset\n",
        "        return float(1.0 - 1.0 / n_selected)\n",
        "\n",
        "    def oracle(self, x: np.ndarray) -> float:\n",
        "\n",
        "        x = np.asarray(x, dtype=np.int8)\n",
        "\n",
        "        ret = self.portfolio_return(x)\n",
        "        risk = self.portfolio_risk(x)\n",
        "        div = self.portfolio_diversification(x)\n",
        "        return -ret + self.risk_weight * risk - self.diversity_weight * div\n",
        "\n",
        "    def sample_feasible(self, rng: np.random.Generator, n: int) -> np.ndarray:\n",
        "        \"\"\"Generate n feasible portfolios (exactly K assets selected).\"\"\"\n",
        "        if self.K > self.d or self.K < 0:\n",
        "            raise ValueError(f\"Cannot select K={self.K} assets from d={self.d}\")\n",
        "\n",
        "        X = np.zeros((int(n), self.d), dtype=np.int8)\n",
        "        for i in range(int(n)):\n",
        "            indices = select_k_from_n(self.d,self.K,rng)\n",
        "            X[i, indices] = 1\n",
        "        return X\n",
        "    def info(self) -> Dict:\n",
        "        return {\n",
        "            \"name\": self.name,\n",
        "            \"d\": self.d,\n",
        "            \"K\": self.K,\n",
        "            \"seed\": self.seed,\n",
        "            \"avg_return\": float(np.mean(self.returns)),\n",
        "            \"avg_risk\": float(np.mean(self.risks)),\n",
        "            \"return_scale\": self.return_scale,\n",
        "            \"risk_scale\": self.risk_scale,\n",
        "            \"diversity_weight\": self.diversity_weight,\n",
        "            \"risk_weight\": self.risk_weight,\n",
        "        }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ar7IeYboBHe6"
      },
      "source": [
        "loop.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "-KiR5dvdBIvs"
      },
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "import time\n",
        "from dataclasses import dataclass\n",
        "from pathlib import Path\n",
        "from typing import Any, Dict, Optional, Tuple\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import yaml\n",
        "\n",
        "#from .benchmarks import KnapsackBenchmark, MaxCutCardinalityBenchmark, OneHotQUBOBenchmark\n",
        "#from .constraints import Constraint, batch_is_feasible\n",
        "#from .data import DataBuffer\n",
        "#from .fm import FMTrainConfig, fm_predict_proba, fm_predict_reg, fm_to_qubo, train_fm_classifier, train_fm_regression\n",
        "#from .surrogate import SurrogateObjective\n",
        "#from .utils import ensure_dir, save_json, set_global_seed, topk_unique, select_diverse_topk, spearmanr_np\n",
        "#from .solvers import CEMSolver, ProtesSolver, RandomSolver, has_protes\n",
        "#from .solvers.sa_solver import SASolver, has_sa\n",
        "#from .solvers.exact_enum_solver import ExactEnumSolver\n",
        "#from .solvers.tabu_solver import TabuSolver, has_tabu\n",
        "#from .solvers.qbsolv_solver import QBSolvSolver, QBSolvConfig, has_qbsolv\n",
        "\n",
        "\n",
        "def build_benchmark(cfg: Dict[str, Any]):\n",
        "    kind = cfg[\"kind\"].lower()\n",
        "    if kind == \"maxcut_cardinality\":\n",
        "        return MaxCutCardinalityBenchmark(\n",
        "            d=int(cfg.get(\"d\", 60)),\n",
        "            K=int(cfg.get(\"K\", 20)),\n",
        "            seed=int(cfg.get(\"seed\", 0)),\n",
        "            weight_scale=float(cfg.get(\"weight_scale\", 1.0)),\n",
        "        )\n",
        "    if kind == \"knapsack\":\n",
        "        return KnapsackBenchmark(\n",
        "            d=int(cfg.get(\"d\", 200)),\n",
        "            seed=int(cfg.get(\"seed\", 0)),\n",
        "            capacity_ratio=float(cfg.get(\"capacity_ratio\", 0.35)),\n",
        "        )\n",
        "    if kind == \"onehot_qubo\":\n",
        "        return OneHotQUBOBenchmark(\n",
        "            group_sizes=cfg.get(\"group_sizes\", [5, 5, 5, 5]),\n",
        "            seed=int(cfg.get(\"seed\", 0)),\n",
        "            interaction_scale=float(cfg.get(\"interaction_scale\", 1.0)),\n",
        "            planted_bias=float(cfg.get(\"planted_bias\", 2.0)),\n",
        "        )\n",
        "    if kind == \"portfolio\":\n",
        "        return PortfolioBenchmark(\n",
        "            d=int(cfg.get(\"d\", 50)),\n",
        "            K=int(cfg.get(\"K\", 10)),\n",
        "            seed=int(cfg.get(\"seed\", 0)),\n",
        "            return_scale=float(cfg.get(\"return_scale\", 0.1)),\n",
        "            risk_scale=float(cfg.get(\"risk_scale\", 0.3)),\n",
        "            diversity_weight=float(cfg.get(\"diversity_weight\", 0.1)),\n",
        "            risk_weight=float(cfg.get(\"risk_weight\", 5.0)),\n",
        "        )\n",
        "    raise ValueError(f\"Unknown benchmark kind: {kind}\")\n",
        "\n",
        "\n",
        "def build_solver(cfg: Dict[str, Any], *, bench=None, cons=None):\n",
        "    kind = cfg[\"kind\"].lower()\n",
        "\n",
        "    if kind == \"protes\":\n",
        "        if not has_protes():\n",
        "            print(\"[warn] solver.kind=protes but protes is not installed; falling back to CEM\")\n",
        "            kind = \"cem\"\n",
        "        else:\n",
        "            return ProtesSolver(\n",
        "                batch_size=int(cfg.get(\"batch_size\", 256)),\n",
        "                elite_size=int(cfg.get(\"elite_size\", 20)),\n",
        "                k_gd=int(cfg.get(\"k_gd\", 1)),\n",
        "                lr=float(cfg.get(\"lr\", 5e-2)),\n",
        "                r=int(cfg.get(\"r\", 5)),\n",
        "                log=bool(cfg.get(\"log\", False)),\n",
        "            )\n",
        "\n",
        "    if kind == \"cem\":\n",
        "        return CEMSolver(\n",
        "            batch_size=int(cfg.get(\"batch_size\", 512)),\n",
        "            elite_frac=float(cfg.get(\"elite_frac\", 0.1)),\n",
        "            n_iters=int(cfg.get(\"n_iters\", 50)),\n",
        "            lr=float(cfg.get(\"lr\", 0.7)),\n",
        "            init_p=float(cfg.get(\"init_p\", 0.5)),\n",
        "        )\n",
        "\n",
        "    if kind == \"random\":\n",
        "        return RandomSolver(p_one=float(cfg.get(\"p_one\", 0.5)))\n",
        "\n",
        "    if kind == \"exact_enum\":\n",
        "        return ExactEnumSolver(\n",
        "            max_d=int(cfg.get(\"max_d\", 24)),\n",
        "            batch_eval=int(cfg.get(\"batch_eval\", 8192)),\n",
        "        )\n",
        "\n",
        "    if kind == \"sa\":\n",
        "        if not has_sa():\n",
        "            raise RuntimeError(\"solver.kind=sa requires 'dimod' and 'dwave-neal'. Install: pip install dimod dwave-neal\")\n",
        "        return SASolver(\n",
        "            num_sweeps=int(cfg.get(\"num_sweeps\", 2000)),\n",
        "            beta_range=tuple(cfg[\"beta_range\"]) if \"beta_range\" in cfg and cfg[\"beta_range\"] is not None else None,\n",
        "        )\n",
        "\n",
        "    if kind == \"tabu\":\n",
        "        if not has_tabu():\n",
        "            raise RuntimeError(\"solver.kind=tabu requires 'dimod' and 'dwave-tabu'. Install: pip install dimod dwave-tabu\")\n",
        "        return TabuSolver(\n",
        "            timeout=int(cfg.get(\"timeout\", 1000)),\n",
        "            tenure=int(cfg[\"tenure\"]) if \"tenure\" in cfg and cfg[\"tenure\"] is not None else None,\n",
        "        )\n",
        "\n",
        "    if kind == \"qbsolv\":\n",
        "        if not has_qbsolv():\n",
        "            raise RuntimeError(\"solver.kind=qbsolv requires 'dimod' and 'dwave-samplers'. Install: pip install dimod dwave-samplers\")\n",
        "        qbcfg = QBSolvConfig(\n",
        "            subproblem_size=int(cfg.get(\"subproblem_size\", 400)),\n",
        "            max_outer_iters=int(cfg.get(\"max_outer_iters\", 50)),\n",
        "            max_no_improve=int(cfg.get(\"max_no_improve\", 10)),\n",
        "            tol=float(cfg.get(\"tol\", 0.0)),\n",
        "            sub_num_reads=int(cfg.get(\"sub_num_reads\", 200)),\n",
        "            sub_num_sweeps=int(cfg.get(\"sub_num_sweeps\", 1000)),\n",
        "            sub_beta_range=tuple(cfg[\"sub_beta_range\"]) if cfg.get(\"sub_beta_range\") is not None else None,\n",
        "            polish_with_steepest_descent=bool(cfg.get(\"polish_with_steepest_descent\", True)),\n",
        "            candidates_per_subproblem=int(cfg.get(\"candidates_per_subproblem\", 25)),\n",
        "        )\n",
        "        return QBSolvSolver(cfg=qbcfg)\n",
        "\n",
        "    raise ValueError(f\"Unknown solver kind: {kind}\")\n",
        "\n",
        "\n",
        "def init_dataset(\n",
        "    bench,\n",
        "    cons: Optional[Constraint],\n",
        "    cfg: Dict[str, Any],\n",
        "    rng: np.random.Generator,\n",
        ") -> DataBuffer:\n",
        "    data = DataBuffer()\n",
        "\n",
        "    mode = cfg.get(\"mode\", \"generate\").lower()\n",
        "    if mode == \"generate\":\n",
        "        n0 = int(cfg.get(\"n_feasible\", 200))\n",
        "        X0 = bench.sample_feasible(rng, n0)\n",
        "        #comm\n",
        "        for x in X0:\n",
        "            y = bench.oracle(x)\n",
        "            data.add_point(x, feasible=True, y=y)\n",
        "\n",
        "        # Add some infeasible samples for the classifier (optional but recommended)\n",
        "        n_neg = int(cfg.get(\"n_infeasible\", 250))#EDIT\n",
        "        d = bench.n_vars()\n",
        "        for _ in range(n_neg):\n",
        "            x = (rng.random(d) < 0.5).astype(np.int8)\n",
        "            feasible = True if cons is None else cons.is_feasible(x)\n",
        "            data.add_clf(x, 1 if feasible else 0)\n",
        "\n",
        "    elif mode == \"load_npz\":\n",
        "        path = Path(cfg[\"path\"])\n",
        "        arr = np.load(path)\n",
        "        X = arr[\"X\"].astype(np.int8)\n",
        "        y = arr[\"y\"].astype(np.float64)\n",
        "        if X.ndim != 2:\n",
        "            raise ValueError(\"X in npz must be 2D\")\n",
        "        if len(X) != len(y):\n",
        "            raise ValueError(\"X and y sizes mismatch in npz\")\n",
        "        for xi, yi in zip(X, y):\n",
        "            # assume loaded points are feasible\n",
        "            data.add_point(xi, feasible=True, y=float(yi))\n",
        "\n",
        "        # Optionally add negatives\n",
        "        n_neg = int(cfg.get(\"n_infeasible\", 0))\n",
        "        d = X.shape[1]\n",
        "        for _ in range(n_neg):\n",
        "            x = (rng.random(d) < 0.5).astype(np.int8)\n",
        "            feasible = True if cons is None else cons.is_feasible(x)\n",
        "            data.add_clf(x, 1 if feasible else 0)\n",
        "\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown init_dataset.mode: {mode}\")\n",
        "\n",
        "    return data\n",
        "\n",
        "\n",
        "def run_experiment(config: Dict[str, Any], out_dir: str | Path) -> Path:\n",
        "    out_dir = ensure_dir(out_dir)\n",
        "\n",
        "    seed = int(config.get(\"seed\", 0))\n",
        "    set_global_seed(seed)\n",
        "    rng = np.random.default_rng(seed)\n",
        "\n",
        "    print(\"building benchmark\")\n",
        "    bench = build_benchmark(config[\"benchmark\"])\n",
        "\n",
        "    print(\"building constraints\")\n",
        "    cons = bench.constraint()\n",
        "\n",
        "    # Save config + benchmark info\n",
        "    print(\"save benchmark info to\",out_dir,\"/benchmark.json\")\n",
        "    save_json(out_dir / \"benchmark.json\", bench.info())\n",
        "\n",
        "    # Initial data\n",
        "    print(\"init dataset\")\n",
        "    data = init_dataset(bench, cons, config.get(\"init_dataset\", {}), rng)\n",
        "\n",
        "    d = bench.n_vars()\n",
        "\n",
        "    # Training configs\n",
        "    fm_reg_cfg = FMTrainConfig(**config.get(\"fm_reg\", {}))\n",
        "    fm_clf_cfg = FMTrainConfig(**config.get(\"fm_clf\", {}))\n",
        "\n",
        "    # Loop configs\n",
        "    n_iters = int(config.get(\"n_iters\", 30))\n",
        "    top_k = int(config.get(\"top_k\", 20))\n",
        "    solver_budget = int(config.get(\"solver_budget\", 5000))\n",
        "    candidate_pool_k = int(config.get(\"candidate_pool_k\", 500))  # top unique from solver pool\n",
        "\n",
        "    rho = float(config.get(\"penalty\", {}).get(\"rho\", 0.0))\n",
        "    penalty_cfg = config.get(\"penalty\", {})\n",
        "    rho_adapt = bool(penalty_cfg.get(\"adaptive\", False))\n",
        "    rho_target = float(penalty_cfg.get(\"target_feasible_rate\", 0.3))\n",
        "    rho_grow = float(penalty_cfg.get(\"grow\", 2.0))\n",
        "    rho_shrink = float(penalty_cfg.get(\"shrink\", 0.9))\n",
        "    rho_min = float(penalty_cfg.get(\"min_rho\", 0.0))\n",
        "    rho_max = float(penalty_cfg.get(\"max_rho\", 1e9))\n",
        "\n",
        "    alpha = float(config.get(\"feasibility_term\", {}).get(\"alpha\", 0.0))\n",
        "    use_clf = bool(config.get(\"feasibility_term\", {}).get(\"enabled\", False))\n",
        "    min_clf_points = int(config.get(\"feasibility_term\", {}).get(\"min_points\", 200))\n",
        "\n",
        "    cand_cfg = config.get(\"candidate_selection\", {})\n",
        "    min_hamming = int(cand_cfg.get(\"min_hamming\", 0))\n",
        "\n",
        "    print(\"building solver:\",config[\"solver\"])\n",
        "    solver = build_solver(config[\"solver\"], bench=bench, cons=cons)\n",
        "\n",
        "    # Tracking best\n",
        "    best_y = float(\"inf\")\n",
        "    best_x = None\n",
        "    oracle_calls = 0\n",
        "\n",
        "    rows = []\n",
        "    t00=time.time()\n",
        "    for it in range(n_iters):\n",
        "        print(\"iteration:\",it,\"/\",n_iters)\n",
        "        t0 = time.time()\n",
        "\n",
        "        # --- Train FM regression (feasible only)\n",
        "        X_reg, y_reg = data.get_reg_arrays()\n",
        "        if X_reg.shape[0] < 2:\n",
        "            raise RuntimeError(\"Not enough feasible data to train regression FM\")\n",
        "        print(\"training FM!\")\n",
        "        fm_reg, reg_info = train_fm_regression(\n",
        "            X_reg, y_reg, fm_reg_cfg, seed=seed + 1000 + it\n",
        "        )\n",
        "        print(\"getting qubo!\")\n",
        "        Q, const = fm_to_qubo(fm_reg)\n",
        "\n",
        "        # Surrogate quality (cheap diagnostics on training set)\n",
        "        try:\n",
        "            y_hat = fm_predict_reg(fm_reg, X_reg).astype(np.float64)\n",
        "            ss_res = float(np.sum((y_reg - y_hat) ** 2))\n",
        "            ss_tot = float(np.sum((y_reg - float(np.mean(y_reg))) ** 2) + 1e-12)\n",
        "            reg_info = {\n",
        "                **reg_info,\n",
        "                \"surrogate_r2_train\": float(1.0 - ss_res / ss_tot),\n",
        "                \"surrogate_spearman_train\": float(spearmanr_np(y_reg, y_hat)),\n",
        "            }\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "        # --- Train feasibility classifier (optional)\n",
        "        p_feasible_fn = None\n",
        "        clf_info = {}\n",
        "        if use_clf and data.size_clf() >= min_clf_points:\n",
        "            X_clf, y_clf = data.get_clf_arrays()\n",
        "            fm_clf, clf_info = train_fm_classifier(\n",
        "                X_clf, y_clf, fm_clf_cfg, seed=seed + 2000 + it\n",
        "            )\n",
        "            p_feasible_fn = lambda X: fm_predict_proba(fm_clf, X)\n",
        "\n",
        "        # --- Build surrogate objective for solver\n",
        "        surrogate = SurrogateObjective(\n",
        "            Q=Q,\n",
        "            const=const,\n",
        "            constraint=cons,\n",
        "            rho=rho,\n",
        "            p_feasible=p_feasible_fn,\n",
        "            alpha=alpha,\n",
        "        )\n",
        "\n",
        "        # --- Solve surrogate with PROTES (or chosen solver)\n",
        "        print(\"solving...!\")\n",
        "        result = solver.solve(\n",
        "            objective=surrogate,\n",
        "            d=d,\n",
        "            budget=solver_budget,\n",
        "            pool_size=candidate_pool_k,\n",
        "            seed=seed + 3000 + it,\n",
        "        )\n",
        "\n",
        "        # Choose top candidates from evaluated pool (unique)\n",
        "        X_pool, y_pool = result.X_pool, result.y_pool\n",
        "\n",
        "        if len(X_pool) == 0:\n",
        "            # fallback: at least evaluate returned best\n",
        "            X_pool = result.X_best.reshape(1, -1)\n",
        "            y_pool = surrogate(X_pool)\n",
        "\n",
        "        X_top, y_top = topk_unique(X_pool, y_pool, k=candidate_pool_k)\n",
        "\n",
        "        # Diverse selection for oracle queries (optional)\n",
        "        if min_hamming > 0:\n",
        "            X_query, _ = select_diverse_topk(X_top, y_top, k=top_k, min_hamming=min_hamming)\n",
        "        else:\n",
        "            X_query = X_top[:top_k] if len(X_top) >= top_k else X_top\n",
        "\n",
        "        # --- Query oracle (feasible only), always log feasibility\n",
        "        feas_mask = batch_is_feasible(X_query, cons)\n",
        "        n_feas = int(np.sum(feas_mask))\n",
        "        n_infeas = int(len(X_query) - n_feas)\n",
        "        feas_rate = float(n_feas / max(1, len(X_query)))\n",
        "\n",
        "        # Optional adaptive penalty update (based on observed feasibility)\n",
        "        if rho_adapt and cons is not None:\n",
        "            if feas_rate < rho_target:\n",
        "                rho = min(rho_max, max(rho_min, rho * rho_grow))\n",
        "            else:\n",
        "                rho = min(rho_max, max(rho_min, rho * rho_shrink))\n",
        "\n",
        "        # Add to classifier dataset\n",
        "        for x, ok in zip(X_query, feas_mask):\n",
        "            data.add_clf(x, 1 if bool(ok) else 0)\n",
        "\n",
        "        print(\"evaluating oracles!\")\n",
        "        # Evaluate oracle on feasible only\n",
        "        y_oracle_new = []\n",
        "        for x, ok in zip(X_query, feas_mask):\n",
        "            if not bool(ok):\n",
        "                #print(sum(x[0:60]),sum(x[60:160]),sum(x[160:170]),sum(x))\n",
        "                continue\n",
        "\n",
        "            y = bench.oracle(x)\n",
        "            oracle_calls += 1\n",
        "            data.add_reg(x, y)\n",
        "            y_oracle_new.append(float(y))\n",
        "            #print('got this!')\n",
        "            if y < best_y:\n",
        "                best_y = float(y)\n",
        "                best_x = x.copy()\n",
        "\n",
        "        dt = time.time() - t0\n",
        "\n",
        "        row = {\n",
        "            \"iter\": it,\n",
        "            \"n_reg\": data.size_reg(),\n",
        "            \"n_clf\": data.size_clf(),\n",
        "            \"oracle_calls\": oracle_calls,\n",
        "            \"query_k\": int(len(X_query)),\n",
        "            \"query_feasible\": n_feas,\n",
        "            \"query_infeasible\": n_infeas,\n",
        "            \"query_feasible_rate\": float(feas_rate),\n",
        "            \"rho\": float(rho),\n",
        "            \"best_y\": best_y,\n",
        "            \"time_sec\": dt,\n",
        "            **reg_info,\n",
        "            **clf_info,\n",
        "            **result.info,\n",
        "        }\n",
        "        rows.append(row)\n",
        "\n",
        "        print(\n",
        "            f\"[iter {it:03d}] best_y={best_y:.6g} | oracle_calls={oracle_calls} | \"\n",
        "            f\"feasible {n_feas}/{len(X_query)} | reg_n={data.size_reg()} | {solver.name}\"\n",
        "        )\n",
        "    print('total time taken by fm_protes is:',time.time()-t00)\n",
        "    print('save outputs!')\n",
        "    # Save outputs\n",
        "    hist = pd.DataFrame(rows)\n",
        "    hist.to_csv(out_dir / \"history.csv\", index=False)\n",
        "\n",
        "    if best_x is None:\n",
        "        best_x = np.zeros((d,), dtype=np.int8)\n",
        "\n",
        "    save_json(out_dir / \"best.json\", {\"best_y\": best_y, \"best_x\": best_x.tolist(), \"oracle_calls\": oracle_calls})\n",
        "    # save config copy as yaml\n",
        "    (out_dir / \"config.yaml\").write_text(yaml.safe_dump(config, sort_keys=False), encoding=\"utf-8\")\n",
        "    print('loop ans')\n",
        "    print(best_x.tolist())\n",
        "    x=best_x.tolist()\n",
        "    bench.print_results(x)\n",
        "    return out_dir,bench\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFBZ4pvh4eSL"
      },
      "source": [
        "QuboSolvers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "3uqHYrG24hwq"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import time\n",
        "#https://github.com/dwavesystems/dwave-samplers\n",
        "from dwave.samplers import SimulatedAnnealingSampler\n",
        "def DWaveQuboSolver(Q,num_reads=10000):\n",
        "    t0=time.time()\n",
        "    sampler = SimulatedAnnealingSampler()\n",
        "    sampleset = sampler.sample_qubo(Q,num_of_samples=num_reads)\n",
        "    print('total time taken:',time.time()-t0)\n",
        "    return sampleset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XDRZFOok9lkq"
      },
      "source": [
        "**Solvers**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "HKdLl2A493z1"
      },
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "from dataclasses import dataclass\n",
        "from typing import Callable, Dict, Optional\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "ObjectiveFn = Callable[[np.ndarray], np.ndarray]\n",
        "\n",
        "@dataclass\n",
        "class SolverResult:\n",
        "    X_pool: np.ndarray          # evaluated candidates (may include infeasible)\n",
        "    y_pool: np.ndarray          # surrogate energies for X_pool\n",
        "    X_best: np.ndarray          # best candidate (surrogate)\n",
        "    y_best: float\n",
        "    info: Dict[str, float]\n",
        "\n",
        "\n",
        "class Solver:\n",
        "    name: str = \"base\"\n",
        "\n",
        "    def solve(\n",
        "        self,\n",
        "        objective: ObjectiveFn,\n",
        "        d: int,\n",
        "        budget: int,\n",
        "        pool_size: int,\n",
        "        seed: int,\n",
        "    ) -> SolverResult:\n",
        "        raise NotImplementedError"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ojQIBCBQCCWL"
      },
      "source": [
        "cem_solver.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "xIJIohcQCFuh"
      },
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "from dataclasses import dataclass\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "#from .base import ObjectiveFn, Solver, SolverResult\n",
        "#from ..utils import topk_unique\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class CEMSolver(Solver):\n",
        "    \"\"\"Cross-Entropy Method baseline (product Bernoulli distribution).\n",
        "\n",
        "    This is NOT TT-based, but is a strong simple baseline and a good fallback\n",
        "    when PROTES is not installed.\n",
        "    \"\"\"\n",
        "\n",
        "    name: str = \"cem\"\n",
        "    batch_size: int = 512\n",
        "    elite_frac: float = 0.1\n",
        "    n_iters: int = 50\n",
        "    lr: float = 0.7\n",
        "    init_p: float = 0.5\n",
        "    min_p: float = 0.01\n",
        "    max_p: float = 0.99\n",
        "\n",
        "    def solve(self, objective: ObjectiveFn, d: int, budget: int, pool_size: int, seed: int) -> SolverResult:\n",
        "        rng = np.random.default_rng(seed)\n",
        "        p = np.full((d,), self.init_p, dtype=np.float64)\n",
        "\n",
        "        # bounded pool (best unique)\n",
        "        X_keep = np.zeros((0, d), dtype=np.int8)\n",
        "        y_keep = np.zeros((0,), dtype=np.float64)\n",
        "\n",
        "        evals = 0\n",
        "        it = 0\n",
        "        X_best = np.zeros((d,), dtype=np.int8)\n",
        "        y_best = float(\"inf\")\n",
        "\n",
        "        while evals < budget and it < self.n_iters:\n",
        "            B = min(self.batch_size, budget - evals)\n",
        "            X = (rng.random((B, d)) < p[None, :]).astype(np.int8)\n",
        "            y = objective(X).astype(np.float64)\n",
        "            evals += int(B)\n",
        "\n",
        "            # track best over all evaluations (even if pool is pruned later)\n",
        "            j = int(np.argmin(y)) if len(y) else 0\n",
        "            if len(y) and float(y[j]) < y_best:\n",
        "                y_best = float(y[j])\n",
        "                X_best = X[j].copy()\n",
        "\n",
        "            # merge into pool + prune\n",
        "            if len(X_keep) == 0:\n",
        "                X_keep, y_keep = X, y\n",
        "            else:\n",
        "                X_keep = np.concatenate([X_keep, X], axis=0)\n",
        "                y_keep = np.concatenate([y_keep, y], axis=0)\n",
        "\n",
        "            if pool_size is not None and int(pool_size) > 0:\n",
        "                cap = int(pool_size)\n",
        "                if len(X_keep) > 2 * cap:\n",
        "                    X_keep, y_keep = topk_unique(X_keep, y_keep, k=cap)\n",
        "\n",
        "            # elite update\n",
        "            elite_n = max(1, int(self.elite_frac * B))\n",
        "            elite_idx = np.argsort(y)[:elite_n]\n",
        "            elite = X[elite_idx]\n",
        "            p_new = np.mean(elite, axis=0)\n",
        "            p = (1.0 - self.lr) * p + self.lr * p_new\n",
        "            p = np.clip(p, self.min_p, self.max_p)\n",
        "\n",
        "            it += 1\n",
        "\n",
        "        # final prune\n",
        "        if pool_size is not None and int(pool_size) > 0 and len(X_keep) > int(pool_size):\n",
        "            X_pool, y_pool = topk_unique(X_keep, y_keep, k=int(pool_size))\n",
        "        else:\n",
        "            X_pool, y_pool = X_keep, y_keep\n",
        "\n",
        "        return SolverResult(\n",
        "            X_pool=X_pool,\n",
        "            y_pool=y_pool,\n",
        "            X_best=X_best,\n",
        "            y_best=float(y_best),\n",
        "            info={\"evaluations\": float(evals), \"iters\": float(it)},\n",
        "        )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHaqVN4RCMkt"
      },
      "source": [
        "exact_enum_solver.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "bRgAR1ryCOnx"
      },
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "from dataclasses import dataclass\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "#from .base import ObjectiveFn, Solver, SolverResult\n",
        "#from ..utils import topk_unique\n",
        "\n",
        "\n",
        "def _enumerate_binary(d: int) -> np.ndarray:\n",
        "    \"\"\"Return all binary vectors of length d as (2^d, d) uint8.\"\"\"\n",
        "    n = 1 << int(d)\n",
        "    I = np.arange(n, dtype=np.uint32)[:, None]\n",
        "    bits = (I >> np.arange(d, dtype=np.uint32)[None, :]) & 1\n",
        "    return bits.astype(np.int8)\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class ExactEnumSolver(Solver):\n",
        "    \"\"\"Exact solver by full enumeration (validation / debugging only).\n",
        "\n",
        "    Evaluates all 2^d candidates; only feasible for small d.\n",
        "    \"\"\"\n",
        "\n",
        "    name: str = \"exact_enum\"\n",
        "    max_d: int = 24\n",
        "    batch_eval: int = 8192  # objective batch size to avoid huge temporary allocations\n",
        "\n",
        "    def solve(self, objective: ObjectiveFn, d: int, budget: int, pool_size: int, seed: int) -> SolverResult:\n",
        "        d = int(d)\n",
        "        if d > int(self.max_d):\n",
        "            raise RuntimeError(f\"ExactEnumSolver: d={d} exceeds max_d={self.max_d} (2^d too large).\")\n",
        "\n",
        "        X_all = _enumerate_binary(d)\n",
        "        n = int(len(X_all))\n",
        "\n",
        "        # budget is ignored by design (this is exact); report true eval count\n",
        "        y_all = np.empty((n,), dtype=np.float64)\n",
        "        for s in range(0, n, int(self.batch_eval)):\n",
        "            xb = X_all[s : s + int(self.batch_eval)]\n",
        "            y_all[s : s + len(xb)] = objective(xb).astype(np.float64)\n",
        "\n",
        "        idx = int(np.argmin(y_all)) if n else 0\n",
        "        X_best = X_all[idx].copy() if n else np.zeros((d,), dtype=np.int8)\n",
        "        y_best = float(y_all[idx]) if n else float(\"inf\")\n",
        "\n",
        "        if pool_size is not None and int(pool_size) > 0 and n > int(pool_size):\n",
        "            X_pool, y_pool = topk_unique(X_all, y_all, k=int(pool_size))\n",
        "        else:\n",
        "            X_pool, y_pool = X_all, y_all\n",
        "\n",
        "        return SolverResult(\n",
        "            X_pool=X_pool,\n",
        "            y_pool=y_pool,\n",
        "            X_best=X_best,\n",
        "            y_best=y_best,\n",
        "            info={\"evaluations\": float(n), \"ignored_budget\": float(budget)},\n",
        "        )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2iWeizTCRAM"
      },
      "source": [
        "protes_solver.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "hDNZ-puDCS9E"
      },
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "from dataclasses import dataclass\n",
        "from typing import Any, Dict, List\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "#from .base import ObjectiveFn, Solver, SolverResult\n",
        "#from ..utils import topk_unique\n",
        "\n",
        "try:\n",
        "    from protes import protes as _protes\n",
        "    _HAS_PROTES = True\n",
        "except Exception:\n",
        "    _HAS_PROTES = False\n",
        "    _protes = None\n",
        "\n",
        "\n",
        "def has_protes() -> bool:\n",
        "    return _HAS_PROTES\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class ProtesSolver(Solver):\n",
        "    \"\"\"PROTES solver wrapper.\n",
        "\n",
        "    Requires:\n",
        "        pip install protes==0.3.12\n",
        "\n",
        "    API reference:\n",
        "        https://pypi.org/project/protes/\n",
        "        https://github.com/anabatsh/PROTES\n",
        "    \"\"\"\n",
        "\n",
        "    name: str = \"protes\"\n",
        "    batch_size: int = 256   # k\n",
        "    elite_size: int = 20    # k_top\n",
        "    k_gd: int = 1\n",
        "    lr: float = 5e-2\n",
        "    r: int = 5\n",
        "    log: bool = False\n",
        "\n",
        "    def solve(self, objective: ObjectiveFn, d: int, budget: int, pool_size: int, seed: int) -> SolverResult:\n",
        "        if not _HAS_PROTES:\n",
        "            raise RuntimeError(\n",
        "                \"PROTES is not installed. Install with: pip install protes==0.3.12 \"\n",
        "                \"(or switch solver.kind to 'cem').\"\n",
        "            )\n",
        "\n",
        "        info: Dict[str, Any] = {}\n",
        "\n",
        "        # Keep a bounded pool (best unique) to avoid storing all samples when budgets get large.\n",
        "        X_keep = np.zeros((0, d), dtype=np.int8)\n",
        "        y_keep = np.zeros((0,), dtype=np.float64)\n",
        "        evals_total = 0\n",
        "\n",
        "        def f_batch(I):\n",
        "            nonlocal X_keep, y_keep, evals_total\n",
        "            X = np.array(I, dtype=np.int8)\n",
        "            y = objective(X).astype(np.float64)\n",
        "            evals_total += int(len(X))\n",
        "\n",
        "            if pool_size is not None and int(pool_size) > 0:\n",
        "                # merge + prune (keep a bit more before pruning to amortize)\n",
        "                if len(X_keep) == 0:\n",
        "                    X_keep, y_keep = X, y\n",
        "                else:\n",
        "                    X_keep = np.concatenate([X_keep, X], axis=0)\n",
        "                    y_keep = np.concatenate([y_keep, y], axis=0)\n",
        "\n",
        "                cap = int(pool_size)\n",
        "                if len(X_keep) > 2 * cap:\n",
        "                    X_keep, y_keep = topk_unique(X_keep, y_keep, k=cap)\n",
        "            else:\n",
        "                # store everything (original behavior)\n",
        "                X_keep = np.concatenate([X_keep, X], axis=0) if len(X_keep) else X\n",
        "                y_keep = np.concatenate([y_keep, y], axis=0) if len(y_keep) else y\n",
        "\n",
        "            return y\n",
        "\n",
        "        i_opt, y_opt = _protes(\n",
        "            f=f_batch,\n",
        "            d=int(d),\n",
        "            n=2,\n",
        "            m=int(budget),\n",
        "            k=int(self.batch_size),\n",
        "            k_top=int(self.elite_size),\n",
        "            k_gd=int(self.k_gd),\n",
        "            lr=float(self.lr),\n",
        "            r=int(self.r),\n",
        "            seed=int(seed),\n",
        "            log=bool(self.log),\n",
        "            info=info,\n",
        "        )\n",
        "\n",
        "        # Final prune to pool_size (if requested)\n",
        "        if pool_size is not None and int(pool_size) > 0 and len(X_keep) > int(pool_size):\n",
        "            X_pool, y_pool = topk_unique(X_keep, y_keep, k=int(pool_size))\n",
        "        else:\n",
        "            X_pool, y_pool = X_keep, y_keep\n",
        "\n",
        "        X_best = np.array(i_opt, dtype=np.int8).reshape((d,))\n",
        "        y_best = float(y_opt)\n",
        "\n",
        "        out_info = {\"evaluations\": float(evals_total), \"returned_y\": float(y_opt)}\n",
        "        for k, v in info.items():\n",
        "            if isinstance(v, (int, float, np.number)):\n",
        "                out_info[f\"protes_{k}\"] = float(v)\n",
        "\n",
        "        return SolverResult(\n",
        "            X_pool=X_pool,\n",
        "            y_pool=y_pool,\n",
        "            X_best=X_best,\n",
        "            y_best=y_best,\n",
        "            info=out_info,\n",
        "        )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8oxd97fCWso"
      },
      "source": [
        "qbsolv_solver.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "riszzvmXCYxd"
      },
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "from dataclasses import dataclass\n",
        "from typing import Dict, Optional, Tuple\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "#from .base import ObjectiveFn, Solver, SolverResult\n",
        "#from ..constraints import CardinalityConstraint\n",
        "#from ..utils import topk_unique\n",
        "\n",
        "try:\n",
        "    import dimod  # noqa: F401\n",
        "    from dwave.samplers import SimulatedAnnealingSampler, SteepestDescentSolver\n",
        "    _HAS_QBSOLV = True\n",
        "except Exception:\n",
        "    _HAS_QBSOLV = False\n",
        "    SimulatedAnnealingSampler = None  # type: ignore\n",
        "    SteepestDescentSolver = None  # type: ignore\n",
        "\n",
        "\n",
        "def has_qbsolv() -> bool:\n",
        "    return _HAS_QBSOLV\n",
        "\n",
        "\n",
        "def _qubo_from_upper(Q: np.ndarray) -> Dict[Tuple[int, int], float]:\n",
        "    Q = np.asarray(Q, dtype=np.float64)\n",
        "    d = int(Q.shape[0])\n",
        "    qubo: Dict[Tuple[int, int], float] = {}\n",
        "    for i in range(d):\n",
        "        v = float(Q[i, i])\n",
        "        if v:\n",
        "            qubo[(i, i)] = v\n",
        "    for i in range(d):\n",
        "        for j in range(i + 1, d):\n",
        "            v = float(Q[i, j])\n",
        "            if v:\n",
        "                qubo[(i, j)] = v\n",
        "    return qubo\n",
        "\n",
        "\n",
        "def _add_cardinality_penalty_inplace(\n",
        "    qubo: Dict[Tuple[int, int], float],\n",
        "    *,\n",
        "    d: int,\n",
        "    K: int,\n",
        "    rho: float,\n",
        ") -> float:\n",
        "    # rho*(sum x - K)^2, where (sum x)^2 = sum x_i + 2*sum_{i<j} x_i x_j (binary)\n",
        "    lin = float(rho) * (1.0 - 2.0 * float(K))\n",
        "    for i in range(int(d)):\n",
        "        qubo[(i, i)] = float(qubo.get((i, i), 0.0) + lin)\n",
        "\n",
        "    quad = 2.0 * float(rho)\n",
        "    if quad:\n",
        "        for i in range(int(d)):\n",
        "            for j in range(i + 1, int(d)):\n",
        "                qubo[(i, j)] = float(qubo.get((i, j), 0.0) + quad)\n",
        "\n",
        "    return float(rho) * float(K) * float(K)\n",
        "\n",
        "\n",
        "@dataclass(frozen=True)\n",
        "class QBSolvConfig:\n",
        "    subproblem_size: int = 400\n",
        "    max_outer_iters: int = 50\n",
        "    max_no_improve: int = 10\n",
        "    tol: float = 0.0\n",
        "\n",
        "    # subQUBO optimizer = Simulated Annealing\n",
        "    sub_num_reads: int = 200\n",
        "    sub_num_sweeps: int = 1000\n",
        "    sub_beta_range: Optional[Tuple[float, float]] = None\n",
        "\n",
        "    # Optional polish\n",
        "    polish_with_steepest_descent: bool = True\n",
        "\n",
        "    # How many candidate full solutions to keep per subproblem (limits memory)\n",
        "    candidates_per_subproblem: int = 25\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class QBSolvSolver(Solver):\n",
        "    \"\"\"QBSOLV-style decomposition baseline (NO tabu), subsolver = SA.\n",
        "\n",
        "    Works on a QUBO/BQM; in this repo it supports:\n",
        "      - pure FM QUBO\n",
        "      - + cardinality penalty rho*(sum-K)^2\n",
        "    Not supported:\n",
        "      - feasibility classifier term (-alpha*log p)\n",
        "      - non-quadratic violations (e.g., knapsack hinge)\n",
        "    \"\"\"\n",
        "\n",
        "    name: str = \"qbsolv\"\n",
        "    cfg: QBSolvConfig = QBSolvConfig()\n",
        "\n",
        "    def solve(self, objective: ObjectiveFn, d: int, budget: int, pool_size: int, seed: int) -> SolverResult:\n",
        "        if not _HAS_QBSOLV:\n",
        "            raise RuntimeError(\"QBSolvSolver requires 'dimod' and 'dwave-samplers'. Install: pip install dimod dwave-samplers\")\n",
        "\n",
        "        # Expect SurrogateObjective-like object\n",
        "        Q = getattr(objective, \"Q\", None)\n",
        "        const = float(getattr(objective, \"const\", 0.0))\n",
        "        constraint = getattr(objective, \"constraint\", None)\n",
        "        rho = float(getattr(objective, \"rho\", 0.0))\n",
        "        alpha = float(getattr(objective, \"alpha\", 0.0))\n",
        "        p_feasible = getattr(objective, \"p_feasible\", None)\n",
        "\n",
        "        if Q is None:\n",
        "            raise ValueError(\"QBSolvSolver requires objective.Q (expected SurrogateObjective).\")\n",
        "        if p_feasible is not None and alpha != 0.0:\n",
        "            raise RuntimeError(\"QBSolvSolver cannot include -alpha*log(p_feasible); disable feasibility_term for qbsolv.\")\n",
        "        if constraint is not None and rho != 0.0 and not isinstance(constraint, CardinalityConstraint):\n",
        "            raise RuntimeError(\n",
        "                \"QBSolvSolver only supports quadratic penalties in this repo. \"\n",
        "                \"Supported: CardinalityConstraint with rho*(sum-K)^2.\"\n",
        "            )\n",
        "\n",
        "        import dimod  # local import\n",
        "\n",
        "        qubo = _qubo_from_upper(np.asarray(Q, dtype=np.float64))\n",
        "        offset = float(const)\n",
        "        if isinstance(constraint, CardinalityConstraint) and rho != 0.0:\n",
        "            offset += _add_cardinality_penalty_inplace(qubo, d=int(d), K=int(constraint.K), rho=float(rho))\n",
        "\n",
        "        bqm = dimod.BinaryQuadraticModel.from_qubo(qubo, offset=offset)\n",
        "\n",
        "        rng = np.random.default_rng(int(seed))\n",
        "        n = int(d)\n",
        "\n",
        "        # caches for fast energy + impact ordering\n",
        "        linear = np.zeros(n, dtype=np.float64)\n",
        "        for v, bias in bqm.linear.items():\n",
        "            linear[int(v)] = float(bias)\n",
        "\n",
        "        adj: list[list[tuple[int, float]]] = [[] for _ in range(n)]\n",
        "        for (u, v), w in bqm.quadratic.items():\n",
        "            iu = int(u); iv = int(v)\n",
        "            ww = float(w)\n",
        "            adj[iu].append((iv, ww))\n",
        "            adj[iv].append((iu, ww))\n",
        "\n",
        "        def energy_full(x: np.ndarray) -> float:\n",
        "            e = float(bqm.offset) + float(np.dot(linear, x.astype(np.float64)))\n",
        "            for i in range(n):\n",
        "                xi = int(x[i])\n",
        "                if not xi:\n",
        "                    continue\n",
        "                for j, w in adj[i]:\n",
        "                    if j > i and x[j]:\n",
        "                        e += float(w)\n",
        "            return float(e)\n",
        "\n",
        "        def order_by_impact(x: np.ndarray) -> np.ndarray:\n",
        "            field = linear.copy()\n",
        "            # field_i = h_i + sum_j J_ij x_j\n",
        "            for i in range(n):\n",
        "                if not x[i]:\n",
        "                    continue\n",
        "                for j, w in adj[i]:\n",
        "                    field[j] += float(w)\n",
        "            delta = (1.0 - 2.0 * x.astype(np.float64)) * field\n",
        "            return np.argsort(-np.abs(delta))\n",
        "\n",
        "        def decompose_subbqm(subset: np.ndarray, xbest_fixed: np.ndarray) -> \"dimod.BinaryQuadraticModel\":\n",
        "            in_subset = np.zeros(n, dtype=bool)\n",
        "            in_subset[subset] = True\n",
        "\n",
        "            lin: Dict[int, float] = {}\n",
        "            quad: Dict[Tuple[int, int], float] = {}\n",
        "\n",
        "            for iu in subset.astype(int):\n",
        "                bias_u = float(linear[iu])\n",
        "                for iv, w in adj[iu]:\n",
        "                    if in_subset[iv]:\n",
        "                        if iu < iv:\n",
        "                            quad[(iu, iv)] = quad.get((iu, iv), 0.0) + float(w)\n",
        "                    else:\n",
        "                        if xbest_fixed[iv]:\n",
        "                            bias_u += float(w)\n",
        "                lin[iu] = bias_u\n",
        "\n",
        "            return dimod.BinaryQuadraticModel(lin, quad, 0.0, dimod.BINARY)\n",
        "\n",
        "        sa = SimulatedAnnealingSampler()\n",
        "        sd = SteepestDescentSolver() if bool(self.cfg.polish_with_steepest_descent) else None\n",
        "\n",
        "        # Initialize Xbest\n",
        "        Xbest = rng.integers(0, 2, size=n, dtype=np.int8)\n",
        "        best_energy = energy_full(Xbest)\n",
        "\n",
        "        index = order_by_impact(Xbest)\n",
        "\n",
        "        X_pool = np.zeros((0, n), dtype=np.int8)\n",
        "        y_pool = np.zeros((0,), dtype=np.float64)\n",
        "\n",
        "        no_improve = 0\n",
        "        outer_done = 0\n",
        "\n",
        "        for outer in range(1, int(self.cfg.max_outer_iters) + 1):\n",
        "            outer_done = outer\n",
        "            X = Xbest.copy()\n",
        "            E = float(best_energy)\n",
        "\n",
        "            for start in range(0, n, int(self.cfg.subproblem_size)):\n",
        "                subset = index[start : start + int(self.cfg.subproblem_size)]\n",
        "                if subset.size == 0:\n",
        "                    continue\n",
        "\n",
        "                sub_bqm = decompose_subbqm(subset, Xbest)\n",
        "\n",
        "                # seed initial state from Xbest restricted to sub vars\n",
        "                init = {int(v): int(Xbest[int(v)]) for v in sub_bqm.variables}\n",
        "                init_ss = dimod.SampleSet.from_samples(init, vartype=dimod.BINARY, energy=0.0)\n",
        "\n",
        "                sa_kwargs = dict(\n",
        "                    num_reads=int(self.cfg.sub_num_reads),\n",
        "                    num_sweeps=int(self.cfg.sub_num_sweeps),\n",
        "                    seed=int(seed),\n",
        "                    initial_states=init_ss,\n",
        "                    initial_states_generator=\"tile\",\n",
        "                )\n",
        "                if self.cfg.sub_beta_range is not None:\n",
        "                    sa_kwargs[\"beta_range\"] = list(self.cfg.sub_beta_range)\n",
        "\n",
        "                ss = sa.sample(sub_bqm, **sa_kwargs)\n",
        "                if sd is not None:\n",
        "                    ss = sd.sample(sub_bqm, initial_states=ss)\n",
        "\n",
        "                # take a few best candidates from this subproblem and lift to full X for the pool\n",
        "                R = int(min(int(self.cfg.candidates_per_subproblem), len(ss)))\n",
        "                if R > 0 and pool_size is not None and int(pool_size) > 0:\n",
        "                    # ss is already sorted by energy (lowest first) for these samplers\n",
        "                    for r in range(R):\n",
        "                        x_cand = X.copy()\n",
        "                        sub_sample = ss.record.sample[r]\n",
        "                        # ss.variables is the variable order in record.sample columns\n",
        "                        for col, v in enumerate(ss.variables):\n",
        "                            x_cand[int(v)] = int(sub_sample[col])\n",
        "                        e_cand = energy_full(x_cand)\n",
        "                        X_pool = np.concatenate([X_pool, x_cand.reshape(1, -1)], axis=0)\n",
        "                        y_pool = np.concatenate([y_pool, np.array([e_cand], dtype=np.float64)], axis=0)\n",
        "                    # prune pool periodically\n",
        "                    cap = int(pool_size)\n",
        "                    if len(X_pool) > 2 * cap:\n",
        "                        X_pool, y_pool = topk_unique(X_pool, y_pool, k=cap)\n",
        "\n",
        "                # best sub-solution -> apply to current X\n",
        "                best_sub = ss.first.sample\n",
        "                for v, val in best_sub.items():\n",
        "                    X[int(v)] = 1 if int(val) else 0\n",
        "                E = energy_full(X)\n",
        "\n",
        "            index = order_by_impact(X)\n",
        "\n",
        "            if E < best_energy - float(self.cfg.tol):\n",
        "                Xbest = X\n",
        "                best_energy = float(E)\n",
        "                no_improve = 0\n",
        "            else:\n",
        "                no_improve += 1\n",
        "                if no_improve >= int(self.cfg.max_no_improve):\n",
        "                    break\n",
        "\n",
        "        # finalize pool\n",
        "        if pool_size is not None and int(pool_size) > 0 and len(X_pool) > int(pool_size):\n",
        "            X_pool, y_pool = topk_unique(X_pool, y_pool, k=int(pool_size))\n",
        "\n",
        "        # ensure non-empty pool (loop expects some candidates)\n",
        "        if len(X_pool) == 0:\n",
        "            X_pool = Xbest.reshape(1, -1).copy()\n",
        "            y_pool = np.array([float(best_energy)], dtype=np.float64)\n",
        "\n",
        "        idx = int(np.argmin(y_pool)) if len(y_pool) else 0\n",
        "        X_best = X_pool[idx].copy()\n",
        "        y_best = float(y_pool[idx])\n",
        "\n",
        "        return SolverResult(\n",
        "            X_pool=X_pool,\n",
        "            y_pool=y_pool,\n",
        "            X_best=X_best,\n",
        "            y_best=y_best,\n",
        "            info={\n",
        "                \"evaluations\": float(len(X_pool)),  # surrogate energies computed into the returned pool\n",
        "                \"qbsolv_outer_iters\": float(outer_done),\n",
        "            },\n",
        "        )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WMRDqtDnCcrS"
      },
      "source": [
        "random_solver.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "A0lI0iBvCfZu"
      },
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "from dataclasses import dataclass\n",
        "from typing import Callable, Optional\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "#from .base import ObjectiveFn, Solver, SolverResult\n",
        "#from ..utils import topk_unique\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class RandomSolver(Solver):\n",
        "    \"\"\"Random search baseline (unconstrained sampling; feasibility handled by surrogate penalty / clf term).\"\"\"\n",
        "\n",
        "    name: str = \"random\"\n",
        "    p_one: float = 0.5\n",
        "\n",
        "    def solve(self, objective: ObjectiveFn, d: int, budget: int, pool_size: int, seed: int) -> SolverResult:\n",
        "        rng = np.random.default_rng(seed)\n",
        "        B = int(budget)  # must respect evaluation budget\n",
        "        X = (rng.random((B, d)) < self.p_one).astype(np.int8)\n",
        "        y = objective(X).astype(np.float64)\n",
        "\n",
        "        idx = int(np.argmin(y)) if len(y) else 0\n",
        "        X_best = X[idx].copy() if len(y) else np.zeros((d,), dtype=np.int8)\n",
        "        y_best = float(y[idx]) if len(y) else float(\"inf\")\n",
        "\n",
        "        # bounded pool\n",
        "        if pool_size is not None and int(pool_size) > 0 and len(X) > int(pool_size):\n",
        "            X_pool, y_pool = topk_unique(X, y, k=int(pool_size))\n",
        "        else:\n",
        "            X_pool, y_pool = X, y\n",
        "\n",
        "        return SolverResult(\n",
        "            X_pool=X_pool,\n",
        "            y_pool=y_pool,\n",
        "            X_best=X_best,\n",
        "            y_best=y_best,\n",
        "            info={\"evaluations\": float(B)},\n",
        "        )\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class RandomFeasibleSolver(Solver):\n",
        "    \"\"\"Random feasible sampling baseline (matches guide baseline: 'Random feasible sampling').\n",
        "\n",
        "    Requires a feasible sampler (typically Benchmark.sample_feasible).\n",
        "    \"\"\"\n",
        "\n",
        "    name: str = \"random_feasible\"\n",
        "    sample_feasible: Callable[[np.random.Generator, int], np.ndarray] = None  # (rng, n) -> (n,d) feasible\n",
        "\n",
        "    def solve(self, objective: ObjectiveFn, d: int, budget: int, pool_size: int, seed: int) -> SolverResult:\n",
        "        if self.sample_feasible is None:\n",
        "            raise RuntimeError(\"RandomFeasibleSolver requires sample_feasible(rng, n).\")\n",
        "\n",
        "        rng = np.random.default_rng(seed)\n",
        "        B = int(budget)\n",
        "        X = np.asarray(self.sample_feasible(rng, B), dtype=np.int8)\n",
        "        if X.ndim != 2 or X.shape[1] != int(d):\n",
        "            raise ValueError(f\"sample_feasible must return (B,d); got {X.shape}\")\n",
        "\n",
        "        y = objective(X).astype(np.float64)\n",
        "\n",
        "        idx = int(np.argmin(y)) if len(y) else 0\n",
        "        X_best = X[idx].copy() if len(y) else np.zeros((d,), dtype=np.int8)\n",
        "        y_best = float(y[idx]) if len(y) else float(\"inf\")\n",
        "\n",
        "        if pool_size is not None and int(pool_size) > 0 and len(X) > int(pool_size):\n",
        "            X_pool, y_pool = topk_unique(X, y, k=int(pool_size))\n",
        "        else:\n",
        "            X_pool, y_pool = X, y\n",
        "\n",
        "        return SolverResult(\n",
        "            X_pool=X_pool,\n",
        "            y_pool=y_pool,\n",
        "            X_best=X_best,\n",
        "            y_best=y_best,\n",
        "            info={\"evaluations\": float(B)},\n",
        "        )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJHYvMG2CgJn"
      },
      "source": [
        "sa_solver.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "3KG3VGDNCjFC"
      },
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "from dataclasses import dataclass\n",
        "from typing import Any, Dict, Optional, Tuple\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "#from .base import ObjectiveFn, Solver, SolverResult\n",
        "#from ..constraints import CardinalityConstraint\n",
        "#from ..utils import topk_unique\n",
        "\n",
        "try:\n",
        "    import dimod  # noqa: F401\n",
        "    import neal\n",
        "    _HAS_SA = True\n",
        "except Exception:\n",
        "    _HAS_SA = False\n",
        "    neal = None\n",
        "\n",
        "\n",
        "def has_sa() -> bool:\n",
        "    return _HAS_SA\n",
        "\n",
        "\n",
        "def _qubo_from_upper(Q: np.ndarray) -> Dict[Tuple[int, int], float]:\n",
        "    \"\"\"Convert upper-triangular dense Q into a dimod QUBO dict.\"\"\"\n",
        "    Q = np.asarray(Q, dtype=np.float64)\n",
        "    d = Q.shape[0]\n",
        "    qubo: Dict[Tuple[int, int], float] = {}\n",
        "    for i in range(d):\n",
        "        v = float(Q[i, i])\n",
        "        if v != 0.0:\n",
        "            qubo[(i, i)] = v\n",
        "    for i in range(d):\n",
        "        for j in range(i + 1, d):\n",
        "            v = float(Q[i, j])\n",
        "            if v != 0.0:\n",
        "                qubo[(i, j)] = v\n",
        "    return qubo\n",
        "\n",
        "\n",
        "def _add_cardinality_penalty_inplace(\n",
        "    qubo: Dict[Tuple[int, int], float],\n",
        "    *,\n",
        "    d: int,\n",
        "    K: int,\n",
        "    rho: float,\n",
        ") -> float:\n",
        "    \"\"\"Add rho*(sum x - K)^2 to QUBO dict in-place. Returns constant offset added.\"\"\"\n",
        "    # (sum x - K)^2 = (sum x)^2 - 2K sum x + K^2\n",
        "    # (sum x)^2 = sum x_i + 2 * sum_{i<j} x_i x_j   for binary.\n",
        "    # linear: rho*(1 - 2K) per variable\n",
        "    lin = float(rho) * (1.0 - 2.0 * float(K))\n",
        "    for i in range(d):\n",
        "        qubo[(i, i)] = float(qubo.get((i, i), 0.0) + lin)\n",
        "\n",
        "    # quadratic: 2*rho for each i<j\n",
        "    quad = 2.0 * float(rho)\n",
        "    if quad != 0.0:\n",
        "        for i in range(d):\n",
        "            for j in range(i + 1, d):\n",
        "                qubo[(i, j)] = float(qubo.get((i, j), 0.0) + quad)\n",
        "\n",
        "    # constant offset\n",
        "    return float(rho) * float(K) * float(K)\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class SASolver(Solver):\n",
        "    \"\"\"Simulated annealing baseline using dwave-neal.\n",
        "\n",
        "    Notes:\n",
        "    - Requires: dimod + dwave-neal\n",
        "    - Operates on a QUBO/BQM, so it can only handle objectives that are (or can be made) quadratic.\n",
        "    \"\"\"\n",
        "\n",
        "    name: str = \"sa\"\n",
        "    num_sweeps: int = 2000\n",
        "    beta_range: Optional[Tuple[float, float]] = None  # e.g., (0.1, 10.0); None lets neal choose\n",
        "\n",
        "    def solve(self, objective: ObjectiveFn, d: int, budget: int, pool_size: int, seed: int) -> SolverResult:\n",
        "        if not _HAS_SA:\n",
        "            raise RuntimeError(\"SA solver requires 'dimod' and 'dwave-neal'. Install: pip install dimod dwave-neal\")\n",
        "\n",
        "        # Expect SurrogateObjective-like object (from this repo) so we can build a QUBO\n",
        "        Q = getattr(objective, \"Q\", None)\n",
        "        const = getattr(objective, \"const\", 0.0)\n",
        "        constraint = getattr(objective, \"constraint\", None)\n",
        "        rho = float(getattr(objective, \"rho\", 0.0))\n",
        "        alpha = float(getattr(objective, \"alpha\", 0.0))\n",
        "        p_feasible = getattr(objective, \"p_feasible\", None)\n",
        "\n",
        "        if Q is None:\n",
        "            raise ValueError(\"SASolver requires an objective with attribute 'Q' (expected SurrogateObjective).\")\n",
        "\n",
        "        if p_feasible is not None and alpha != 0.0:\n",
        "            raise RuntimeError(\"SASolver cannot include -alpha*log(p_feasible); disable feasibility_term or use another solver.\")\n",
        "\n",
        "        qubo = _qubo_from_upper(np.asarray(Q, dtype=np.float64))\n",
        "        offset = float(const)\n",
        "\n",
        "        # Only support constraint penalty if it stays quadratic (cardinality)\n",
        "        if constraint is not None and rho != 0.0:\n",
        "            if isinstance(constraint, CardinalityConstraint):\n",
        "                offset += _add_cardinality_penalty_inplace(qubo, d=int(d), K=int(constraint.K), rho=float(rho))\n",
        "            else:\n",
        "                raise RuntimeError(\n",
        "                    \"SASolver only supports penalty constraints that are quadratic. \"\n",
        "                    \"Supported: CardinalityConstraint with rho*(sum-K)^2. \"\n",
        "                    \"Use CEM/PROTES for non-quadratic violations.\"\n",
        "                )\n",
        "\n",
        "        import dimod  # local import after dependency check\n",
        "\n",
        "        bqm = dimod.BinaryQuadraticModel.from_qubo(qubo, offset=offset)\n",
        "\n",
        "        sampler = neal.SimulatedAnnealingSampler()\n",
        "\n",
        "        num_reads = int(max(1, budget))  # interpret budget as number of returned SA samples\n",
        "        ss = sampler.sample(\n",
        "            bqm,\n",
        "            num_reads=num_reads,\n",
        "            num_sweeps=int(self.num_sweeps),\n",
        "            beta_range=self.beta_range,\n",
        "            seed=int(seed),\n",
        "        )\n",
        "\n",
        "        # Variables are integer-labeled 0..d-1, so SampleSet order is deterministic.\n",
        "        X = ss.record.sample.astype(np.int8, copy=False)\n",
        "        y = ss.record.energy.astype(np.float64, copy=False)\n",
        "\n",
        "        # pool pruning\n",
        "        if pool_size is not None and int(pool_size) > 0 and len(X) > int(pool_size):\n",
        "            X_pool, y_pool = topk_unique(X, y, k=int(pool_size))\n",
        "        else:\n",
        "            X_pool, y_pool = X, y\n",
        "\n",
        "        idx = int(np.argmin(y_pool)) if len(y_pool) else 0\n",
        "        X_best = X_pool[idx].copy() if len(y_pool) else np.zeros((int(d),), dtype=np.int8)\n",
        "        y_best = float(y_pool[idx]) if len(y_pool) else float(\"inf\")\n",
        "\n",
        "        return SolverResult(\n",
        "            X_pool=X_pool,\n",
        "            y_pool=y_pool,\n",
        "            X_best=X_best,\n",
        "            y_best=y_best,\n",
        "            info={\n",
        "                \"evaluations\": float(num_reads),\n",
        "                \"sa_num_sweeps\": float(self.num_sweeps),\n",
        "            },\n",
        "        )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NUG23C2uCj9S"
      },
      "source": [
        "tabu_solver.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "NRTp9adoCmeD"
      },
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "from dataclasses import dataclass\n",
        "from typing import Dict, Optional, Tuple\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "#from .base import ObjectiveFn, Solver, SolverResult\n",
        "#from ..constraints import CardinalityConstraint\n",
        "#from ..utils import topk_unique\n",
        "\n",
        "try:\n",
        "    import dimod\n",
        "    from tabu import TabuSampler\n",
        "    _HAS_TABU = True\n",
        "except ImportError:\n",
        "    _HAS_TABU = False\n",
        "    TabuSampler = None\n",
        "\n",
        "\n",
        "def has_tabu() -> bool:\n",
        "    return _HAS_TABU\n",
        "\n",
        "\n",
        "def _qubo_from_upper(Q: np.ndarray) -> Dict[Tuple[int, int], float]:\n",
        "    Q = np.asarray(Q, dtype=np.float64)\n",
        "    d = Q.shape[0]\n",
        "    qubo: Dict[Tuple[int, int], float] = {}\n",
        "    # diag\n",
        "    for i in range(d):\n",
        "        v = float(Q[i, i])\n",
        "        if v != 0.0:\n",
        "            qubo[(i, i)] = v\n",
        "    # upper off-diag\n",
        "    for i in range(d):\n",
        "        for j in range(i + 1, d):\n",
        "            v = float(Q[i, j])\n",
        "            if v != 0.0:\n",
        "                qubo[(i, j)] = v\n",
        "    return qubo\n",
        "\n",
        "\n",
        "def _add_cardinality_penalty_inplace(\n",
        "    qubo: Dict[Tuple[int, int], float],\n",
        "    *,\n",
        "    d: int,\n",
        "    K: int,\n",
        "    rho: float,\n",
        ") -> float:\n",
        "    # rho*(sum x - K)^2 where (sum x)^2 = sum x_i + 2*sum_{i<j} x_i x_j for binary\n",
        "    lin = float(rho) * (1.0 - 2.0 * float(K))\n",
        "    for i in range(int(d)):\n",
        "        qubo[(i, i)] = float(qubo.get((i, i), 0.0) + lin)\n",
        "\n",
        "    quad = 2.0 * float(rho)\n",
        "    if quad != 0.0:\n",
        "        for i in range(int(d)):\n",
        "            for j in range(i + 1, int(d)):\n",
        "                qubo[(i, j)] = float(qubo.get((i, j), 0.0) + quad)\n",
        "\n",
        "    return float(rho) * float(K) * float(K)\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class TabuSolver(Solver):\n",
        "    \"\"\"Tabu search baseline using dwave-tabu.\n",
        "\n",
        "    Notes:\n",
        "    - Requires: dimod + dwave-tabu\n",
        "    - QUBO-only: cannot include non-quadratic violations or -alpha*log(p_feasible).\n",
        "    \"\"\"\n",
        "\n",
        "    name: str = \"tabu\"\n",
        "    timeout: int = 1000  # milliseconds per run (dwave-tabu)\n",
        "    tenure: Optional[int] = None  # optional tabu tenure; None lets sampler decide\n",
        "\n",
        "    def solve(self, objective: ObjectiveFn, d: int, budget: int, pool_size: int, seed: int) -> SolverResult:\n",
        "        if not _HAS_TABU:\n",
        "            raise RuntimeError(\"Tabu solver requires 'dimod' and 'dwave-tabu'. Install: pip install dimod dwave-tabu\")\n",
        "\n",
        "        Q = getattr(objective, \"Q\", None)\n",
        "        const = getattr(objective, \"const\", 0.0)\n",
        "        constraint = getattr(objective, \"constraint\", None)\n",
        "        rho = float(getattr(objective, \"rho\", 0.0))\n",
        "        alpha = float(getattr(objective, \"alpha\", 0.0))\n",
        "        p_feasible = getattr(objective, \"p_feasible\", None)\n",
        "\n",
        "        if Q is None:\n",
        "            raise ValueError(\"TabuSolver requires an objective with attribute 'Q' (expected SurrogateObjective).\")\n",
        "\n",
        "        if p_feasible is not None and alpha != 0.0:\n",
        "            raise RuntimeError(\"TabuSolver cannot include -alpha*log(p_feasible); disable feasibility_term or use another solver.\")\n",
        "\n",
        "        qubo = _qubo_from_upper(np.asarray(Q, dtype=np.float64))\n",
        "        offset = float(const)\n",
        "\n",
        "        if constraint is not None and rho != 0.0:\n",
        "            if isinstance(constraint, CardinalityConstraint):\n",
        "                offset += _add_cardinality_penalty_inplace(qubo, d=int(d), K=int(constraint.K), rho=float(rho))\n",
        "            else:\n",
        "                raise RuntimeError(\n",
        "                    \"TabuSolver only supports quadratic penalty constraints. \"\n",
        "                    \"Supported: CardinalityConstraint with rho*(sum-K)^2. \"\n",
        "                    \"Use CEM/PROTES for non-quadratic violations.\"\n",
        "                )\n",
        "\n",
        "        import dimod  # local import after dependency check\n",
        "\n",
        "        bqm = dimod.BinaryQuadraticModel.from_qubo(qubo, offset=offset)\n",
        "        sampler = TabuSampler()\n",
        "\n",
        "        num_reads = int(max(1, budget))  # interpret budget as number of returned samples\n",
        "        kwargs = {\"num_reads\": num_reads, \"timeout\": int(self.timeout)}\n",
        "        if self.tenure is not None:\n",
        "            kwargs[\"tenure\"] = int(self.tenure)\n",
        "\n",
        "        ss = sampler.sample(bqm, **kwargs)\n",
        "\n",
        "        X = ss.record.sample.astype(np.int8, copy=False)\n",
        "        y = ss.record.energy.astype(np.float64, copy=False)\n",
        "\n",
        "        if pool_size is not None and int(pool_size) > 0 and len(X) > int(pool_size):\n",
        "            X_pool, y_pool = topk_unique(X, y, k=int(pool_size))\n",
        "        else:\n",
        "            X_pool, y_pool = X, y\n",
        "\n",
        "        idx = int(np.argmin(y_pool)) if len(y_pool) else 0\n",
        "        X_best = X_pool[idx].copy() if len(y_pool) else np.zeros((int(d),), dtype=np.int8)\n",
        "        y_best = float(y_pool[idx]) if len(y_pool) else float(\"inf\")\n",
        "\n",
        "        return SolverResult(\n",
        "            X_pool=X_pool,\n",
        "            y_pool=y_pool,\n",
        "            X_best=X_best,\n",
        "            y_best=y_best,\n",
        "            info={\n",
        "                \"evaluations\": float(num_reads),\n",
        "                \"tabu_timeout_ms\": float(self.timeout),\n",
        "            },\n",
        "        )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8GzEPHNDAbq"
      },
      "source": [
        "Scripts\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s83X0_doDRTS"
      },
      "source": [
        "aggregate_sweep.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "hDThFIwgDFw9"
      },
      "outputs": [],
      "source": [
        "#!/usr/bin/env python\n",
        "from __future__ import annotations\n",
        "\n",
        "import argparse\n",
        "from pathlib import Path\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def _load_one_history(out_dir: str | Path) -> pd.DataFrame:\n",
        "    out_dir = Path(out_dir)\n",
        "    hist_path = out_dir / \"history.csv\"\n",
        "    if not hist_path.exists():\n",
        "        raise FileNotFoundError(f\"Missing history.csv at: {hist_path}\")\n",
        "    hist = pd.read_csv(hist_path)\n",
        "    # required columns in this repo\n",
        "    need = {\"oracle_calls\", \"best_y\"}\n",
        "    missing = need - set(hist.columns)\n",
        "    if missing:\n",
        "        raise ValueError(f\"{hist_path} missing columns: {sorted(missing)}\")\n",
        "    return hist[[\"oracle_calls\", \"best_y\"]].copy()\n",
        "\n",
        "\n",
        "def aggregate_sweep_main() -> None:\n",
        "    ap = argparse.ArgumentParser()\n",
        "    ap.add_argument(\"--summary\", required=True, help=\"Path to sweep_summary_*.csv\")\n",
        "    ap.add_argument(\"--solver\", default=None, help=\"Filter by solver kind (optional)\")\n",
        "    ap.add_argument(\"--out\", default=None, help=\"Output CSV path (default: alongside summary)\")\n",
        "    ap.add_argument(\"--plot\", action=\"store_true\", help=\"Also save a PNG plot (median + IQR)\")\n",
        "    args = ap.parse_args()\n",
        "\n",
        "    summary_path = Path(args.summary)\n",
        "    df = pd.read_csv(summary_path)\n",
        "\n",
        "    # expected columns from scripts/run_sweep.py\n",
        "    need = {\"out_dir\", \"seed\", \"solver\"}\n",
        "    missing = need - set(df.columns)\n",
        "    if missing:\n",
        "        raise ValueError(f\"{summary_path} missing columns: {sorted(missing)}\")\n",
        "\n",
        "    if args.solver is not None:\n",
        "        df = df[df[\"solver\"].astype(str) == str(args.solver)].copy()\n",
        "\n",
        "    if df.empty:\n",
        "        raise ValueError(\"No runs matched (check --solver filter / summary file).\")\n",
        "\n",
        "    rows = []\n",
        "    for _, r in df.iterrows():\n",
        "        hist = _load_one_history(r[\"out_dir\"])\n",
        "        hist[\"seed\"] = int(r[\"seed\"])\n",
        "        hist[\"solver\"] = str(r[\"solver\"])\n",
        "        rows.append(hist)\n",
        "\n",
        "    all_hist = pd.concat(rows, axis=0, ignore_index=True)\n",
        "\n",
        "    # aggregate per solver (even if only one)\n",
        "    agg = (\n",
        "        all_hist.groupby([\"solver\", \"oracle_calls\"])[\"best_y\"]\n",
        "        .agg(\n",
        "            median=\"median\",\n",
        "            p25=lambda s: s.quantile(0.25),\n",
        "            p75=lambda s: s.quantile(0.75),\n",
        "            n=\"count\",\n",
        "        )\n",
        "        .reset_index()\n",
        "        .sort_values([\"solver\", \"oracle_calls\"])\n",
        "    )\n",
        "\n",
        "    out_csv = Path(args.out) if args.out else summary_path.with_suffix(\"\").with_name(summary_path.stem + \"_agg.csv\")\n",
        "    agg.to_csv(out_csv, index=False)\n",
        "    print(f\"saved: {out_csv}\")\n",
        "\n",
        "    if args.plot:\n",
        "        # one plot per solver (simple, avoids clutter)\n",
        "        for solver_kind, g in agg.groupby(\"solver\"):\n",
        "            x = g[\"oracle_calls\"].to_numpy()\n",
        "            med = g[\"median\"].to_numpy()\n",
        "            p25 = g[\"p25\"].to_numpy()\n",
        "            p75 = g[\"p75\"].to_numpy()\n",
        "\n",
        "            plt.figure()\n",
        "            plt.plot(x, med, label=f\"{solver_kind} median\")\n",
        "            plt.fill_between(x, p25, p75, alpha=0.2, label=\"IQR (p25..p75)\")\n",
        "            plt.xlabel(\"oracle_calls\")\n",
        "            plt.ylabel(\"best_y (lower is better)\")\n",
        "            plt.title(f\"Best feasible objective vs oracle calls ({solver_kind})\")\n",
        "            plt.grid(True)\n",
        "            plt.legend()\n",
        "\n",
        "            out_png = out_csv.with_suffix(\"\").with_name(out_csv.stem + f\"_{solver_kind}_plot.png\")\n",
        "            plt.savefig(out_png, dpi=150, bbox_inches=\"tight\")\n",
        "            plt.close()\n",
        "            print(f\"saved: {out_png}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IK_wPLyVDbIO"
      },
      "source": [
        "plot_history.py\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "9wL_1KbQDfHs"
      },
      "outputs": [],
      "source": [
        "#!/usr/bin/env python\n",
        "from __future__ import annotations\n",
        "\n",
        "import argparse\n",
        "from pathlib import Path\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def plot_history_main(history_file_path:str):\n",
        "    #ap = argparse.ArgumentParser()\n",
        "    #ap.add_argument(\"--history\", required=True, help=\"Path to history.csv\")\n",
        "    #ap.add_argument(\"--x\", default=\"oracle_calls\", choices=[\"iter\", \"oracle_calls\"], help=\"x-axis\")\n",
        "    #args = ap.parse_args()\n",
        "\n",
        "    hist = pd.read_csv(history_file_path)\n",
        "\n",
        "    x = hist[\"oracle_calls\"].values\n",
        "    y = hist[\"best_y\"].values\n",
        "\n",
        "    plt.figure()\n",
        "    plt.plot(x, y, marker=\"o\")\n",
        "    plt.xlabel(\"oracle_calls\")\n",
        "    plt.ylabel(\"best_y (lower is better)\")\n",
        "    plt.title(\"Best feasible objective over time\")\n",
        "    plt.grid(True)\n",
        "    out = Path(history_file_path).with_suffix(\"\").as_posix() + f\"_plot_{\"oracle_calls\"}.png\"\n",
        "    plt.savefig(out, dpi=150, bbox_inches=\"tight\")\n",
        "    print(f\"saved plot to: {out}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_teWlZRDi31"
      },
      "source": [
        "run_sweep.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "dWNGuUa_DnA6"
      },
      "outputs": [],
      "source": [
        "#!/usr/bin/env python\n",
        "from __future__ import annotations\n",
        "\n",
        "import argparse\n",
        "import copy\n",
        "import datetime as dt\n",
        "from pathlib import Path\n",
        "\n",
        "import pandas as pd\n",
        "import yaml\n",
        "\n",
        "import sys\n",
        "#sys.path.append(str(Path(__file__).resolve().parents[1] / \"src\"))\n",
        "\n",
        "#from fm_protes.loop import run_experiment\n",
        "#from fm_protes.utils import ensure_dir\n",
        "\n",
        "\n",
        "def run_sweep_main():\n",
        "    ap = argparse.ArgumentParser()\n",
        "    ap.add_argument(\"--config\", required=True, help=\"Base YAML config\")\n",
        "    ap.add_argument(\"--seeds\", default=\"0,1,2,3,4\", help=\"Comma-separated seeds\")\n",
        "    ap.add_argument(\"--solvers\", default=\"protes,cem,random\", help=\"Comma-separated solver kinds\")\n",
        "    ap.add_argument(\"--out_root\", default=\"results\", help=\"Output root directory\")\n",
        "    args = ap.parse_args()\n",
        "\n",
        "    base_cfg = yaml.safe_load(Path(args.config).read_text(encoding=\"utf-8\"))\n",
        "    seeds = [int(s.strip()) for s in args.seeds.split(\",\") if s.strip()]\n",
        "    solvers = [s.strip() for s in args.solvers.split(\",\") if s.strip()]\n",
        "\n",
        "    out_root = Path(args.out_root)\n",
        "    ensure_dir(out_root)\n",
        "\n",
        "    runs = []\n",
        "    for s in seeds:\n",
        "        for solver_kind in solvers:\n",
        "            cfg = copy.deepcopy(base_cfg)\n",
        "            cfg[\"seed\"] = s\n",
        "            cfg[\"solver\"][\"kind\"] = solver_kind\n",
        "            stamp = dt.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "            run_name = f\"{cfg['benchmark']['kind']}_{solver_kind}_seed{s}_{stamp}\"\n",
        "            out_dir = out_root / run_name\n",
        "            ensure_dir(out_dir)\n",
        "            run_experiment(cfg, out_dir)\n",
        "\n",
        "            hist = pd.read_csv(out_dir / \"history.csv\")\n",
        "            best_y = float(hist[\"best_y\"].iloc[-1])\n",
        "            oracle_calls = int(hist[\"oracle_calls\"].iloc[-1])\n",
        "\n",
        "            runs.append(\n",
        "                {\n",
        "                    \"run_name\": run_name,\n",
        "                    \"solver\": solver_kind,\n",
        "                    \"seed\": s,\n",
        "                    \"best_y\": best_y,\n",
        "                    \"oracle_calls\": oracle_calls,\n",
        "                    \"out_dir\": str(out_dir),\n",
        "                }\n",
        "            )\n",
        "\n",
        "    df = pd.DataFrame(runs)\n",
        "    summary_path = out_root / f\"sweep_summary_{dt.datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\"\n",
        "    df.to_csv(summary_path, index=False)\n",
        "    print(f\"Saved sweep summary: {summary_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KM3enmXzDtwh"
      },
      "source": [
        "run_experiment.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "WZUKZC9qDxox"
      },
      "outputs": [],
      "source": [
        "#!/usr/bin/env python\n",
        "from __future__ import annotations\n",
        "\n",
        "import argparse\n",
        "import datetime as dt\n",
        "from pathlib import Path\n",
        "\n",
        "import yaml\n",
        "\n",
        "# Allow running without installing package:\n",
        "import sys\n",
        "#sys.path.append(str(Path(__file__).resolve().parents[1] / \"src\"))\n",
        "\n",
        "#from fm_protes.loop import run_experiment\n",
        "#from fm_protes.utils import ensure_dir\n",
        "#from fm_protes.solvers import has_protes, has_sa, has_tabu\n",
        "\n",
        "\n",
        "def run_experiment_main(config_file=None,solver_kind=None,n_iters=None,out=None):\n",
        "    #ap = argparse.ArgumentParser()\n",
        "    #ap.add_argument(\"--config\", required=False, help=\"Path to YAML config\")\n",
        "    #ap.add_argument(\"--out\", default=None, help=\"Output directory (default: results/<run_name>)\")\n",
        "    #ap.add_argument(\"--check_deps\", action=\"store_true\", help=\"Print optional dependency status and exit\")\n",
        "\n",
        "    # solver smoke-test helpers\n",
        "    #ap.add_argument(\"--solver_kind\", default=None, help=\"Override solver.kind (e.g. sa, tabu, exact_enum)\")\n",
        "    #ap.add_argument(\"--no_clf\", action=\"store_true\", help=\"Disable feasibility_term (required for sa/tabu here)\")\n",
        "    #ap.add_argument(\"--n_iters\", type=int, default=None, help=\"Override n_iters (for multi-point histories)\")\n",
        "\n",
        "    #args = ap.parse_args()\n",
        "\n",
        "\n",
        "    config=\"_quick.yaml\"\n",
        "    if config_file is not None:\n",
        "        config=config_file\n",
        "    print(\"run experimant\",config)\n",
        "\n",
        "    cfg_path = Path(config)\n",
        "    cfg = yaml.safe_load(cfg_path.read_text(encoding=\"utf-8\"))\n",
        "\n",
        "    if solver_kind is not None:\n",
        "        cfg.setdefault(\"solver\", {})\n",
        "        cfg[\"solver\"][\"kind\"] = str(solver_kind).lower()\n",
        "\n",
        "    if 0: #no_clf:\n",
        "        cfg[\"feasibility_term\"] = {\"enabled\": False, \"alpha\": 0.0, \"min_points\": 0}\n",
        "\n",
        "    if n_iters is not None:\n",
        "        cfg[\"n_iters\"] = int(n_iters)\n",
        "\n",
        "    run_name = cfg.get(\"run_name\")\n",
        "    if not run_name:\n",
        "        stamp = dt.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        run_name = f\"{cfg['benchmark']['kind']}_{stamp}\"\n",
        "\n",
        "    out_dir = Path(out) if out else Path(\"results\") / run_name\n",
        "    ensure_dir(out_dir)\n",
        "\n",
        "    print(f\"[run] config={cfg_path} -> out={out_dir}\")\n",
        "    return run_experiment(cfg, out_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wo7kiMfsD7jM"
      },
      "source": [
        "Main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4vDVqzUtD_Ad",
        "outputId": "a524c110-92d9-4f9d-d2d2-5360b1e8fbc7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "run experimant onehot_qubo.yaml\n",
            "[run] config=onehot_qubo.yaml -> out=results/onehot_qubo_largegroups_hard_onehot\n",
            "building benchmark\n",
            "building constraints\n",
            "save benchmark info to results/onehot_qubo_largegroups_hard_onehot /benchmark.json\n",
            "init dataset\n",
            "building solver: {'kind': 'protes', 'tt_hard_mask': True, 'batch_size': 256, 'elite_size': 20, 'k_gd': 1, 'lr': 0.05, 'r': 5, 'log': False}\n",
            "iteration: 0 / 25\n",
            "training FM!\n",
            "getting qubo!\n",
            "solving...!\n",
            "evaluating oracles!\n",
            "[iter 000] best_y=inf | oracle_calls=0 | feasible 0/25 | reg_n=300 | protes\n",
            "iteration: 1 / 25\n",
            "training FM!\n",
            "getting qubo!\n",
            "solving...!\n",
            "evaluating oracles!\n",
            "[iter 001] best_y=inf | oracle_calls=0 | feasible 0/25 | reg_n=300 | protes\n",
            "iteration: 2 / 25\n",
            "training FM!\n",
            "getting qubo!\n",
            "solving...!\n",
            "evaluating oracles!\n",
            "[iter 002] best_y=inf | oracle_calls=0 | feasible 0/25 | reg_n=300 | protes\n",
            "iteration: 3 / 25\n",
            "training FM!\n",
            "getting qubo!\n",
            "solving...!\n",
            "evaluating oracles!\n",
            "[iter 003] best_y=inf | oracle_calls=0 | feasible 0/25 | reg_n=300 | protes\n",
            "iteration: 4 / 25\n",
            "training FM!\n",
            "getting qubo!\n",
            "solving...!\n",
            "evaluating oracles!\n",
            "[iter 004] best_y=inf | oracle_calls=0 | feasible 0/25 | reg_n=300 | protes\n",
            "iteration: 5 / 25\n",
            "training FM!\n",
            "getting qubo!\n",
            "solving...!\n",
            "evaluating oracles!\n",
            "[iter 005] best_y=inf | oracle_calls=0 | feasible 0/25 | reg_n=300 | protes\n",
            "iteration: 6 / 25\n",
            "training FM!\n",
            "getting qubo!\n",
            "solving...!\n",
            "evaluating oracles!\n",
            "[iter 006] best_y=inf | oracle_calls=0 | feasible 0/25 | reg_n=300 | protes\n",
            "iteration: 7 / 25\n",
            "training FM!\n",
            "getting qubo!\n",
            "solving...!\n",
            "evaluating oracles!\n",
            "[iter 007] best_y=inf | oracle_calls=0 | feasible 0/25 | reg_n=300 | protes\n",
            "iteration: 8 / 25\n",
            "training FM!\n",
            "getting qubo!\n",
            "solving...!\n",
            "evaluating oracles!\n",
            "[iter 008] best_y=inf | oracle_calls=0 | feasible 0/25 | reg_n=300 | protes\n",
            "iteration: 9 / 25\n",
            "training FM!\n",
            "getting qubo!\n",
            "solving...!\n",
            "evaluating oracles!\n",
            "[iter 009] best_y=inf | oracle_calls=0 | feasible 0/25 | reg_n=300 | protes\n",
            "iteration: 10 / 25\n",
            "training FM!\n",
            "getting qubo!\n",
            "solving...!\n",
            "evaluating oracles!\n",
            "[iter 010] best_y=inf | oracle_calls=0 | feasible 0/25 | reg_n=300 | protes\n",
            "iteration: 11 / 25\n",
            "training FM!\n",
            "getting qubo!\n",
            "solving...!\n",
            "evaluating oracles!\n",
            "[iter 011] best_y=inf | oracle_calls=0 | feasible 0/25 | reg_n=300 | protes\n",
            "iteration: 12 / 25\n",
            "training FM!\n",
            "getting qubo!\n",
            "solving...!\n",
            "evaluating oracles!\n",
            "[iter 012] best_y=inf | oracle_calls=0 | feasible 0/25 | reg_n=300 | protes\n",
            "iteration: 13 / 25\n",
            "training FM!\n",
            "getting qubo!\n",
            "solving...!\n",
            "evaluating oracles!\n",
            "[iter 013] best_y=inf | oracle_calls=0 | feasible 0/25 | reg_n=300 | protes\n",
            "iteration: 14 / 25\n",
            "training FM!\n",
            "getting qubo!\n",
            "solving...!\n",
            "evaluating oracles!\n",
            "[iter 014] best_y=inf | oracle_calls=0 | feasible 0/25 | reg_n=300 | protes\n",
            "iteration: 15 / 25\n",
            "training FM!\n",
            "getting qubo!\n",
            "solving...!\n",
            "evaluating oracles!\n",
            "[iter 015] best_y=inf | oracle_calls=0 | feasible 0/25 | reg_n=300 | protes\n",
            "iteration: 16 / 25\n",
            "training FM!\n",
            "getting qubo!\n",
            "solving...!\n",
            "evaluating oracles!\n",
            "[iter 016] best_y=inf | oracle_calls=0 | feasible 0/25 | reg_n=300 | protes\n",
            "iteration: 17 / 25\n",
            "training FM!\n",
            "getting qubo!\n",
            "solving...!\n",
            "evaluating oracles!\n",
            "[iter 017] best_y=inf | oracle_calls=0 | feasible 0/25 | reg_n=300 | protes\n",
            "iteration: 18 / 25\n",
            "training FM!\n",
            "getting qubo!\n",
            "solving...!\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-205216782.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mproblems\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"maxcut_cardinality\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"knapsack\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"onehot_qubo\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"portfolio\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbench\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_experiment_main\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"onehot_qubo.yaml\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mplot_history_main\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m\"history.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1222656358.py\u001b[0m in \u001b[0;36mrun_experiment_main\u001b[0;34m(config_file, solver_kind, n_iters, out)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"[run] config={cfg_path} -> out={out_dir}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrun_experiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-3771875355.py\u001b[0m in \u001b[0;36mrun_experiment\u001b[0;34m(config, out_dir)\u001b[0m\n\u001b[1;32m    289\u001b[0m         \u001b[0;31m# --- Solve surrogate with PROTES (or chosen solver)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"solving...!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m         result = solver.solve(\n\u001b[0m\u001b[1;32m    292\u001b[0m             \u001b[0mobjective\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msurrogate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m             \u001b[0md\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3632276.py\u001b[0m in \u001b[0;36msolve\u001b[0;34m(self, objective, d, budget, pool_size, seed)\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m         i_opt, y_opt = _protes(\n\u001b[0m\u001b[1;32m     82\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mf_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0md\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/protes/protes.py\u001b[0m in \u001b[0;36mprotes\u001b[0;34m(f, d, n, m, k, k_top, k_gd, lr, r, seed, is_max, log, info, P, with_info_p, with_info_i_opt_list, with_info_full, sample_ext, k_rnd, do_final_update)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk_gd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m                 \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mP\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mI\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mwith_info_p\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/jax/_src/pjit.py\u001b[0m in \u001b[0;36mcache_miss\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m     (outs, out_flat, out_tree, args_flat, jaxpr, attrs_tracked, executable,\n\u001b[0;32m--> 337\u001b[0;31m      pgle_profiler) = _python_pjit_helper(fun, jit_info, *args, **kwargs)\n\u001b[0m\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m     maybe_fastpath_data = _get_fastpath_data(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/jax/_src/pjit.py\u001b[0m in \u001b[0;36m_python_pjit_helper\u001b[0;34m(fun, jit_info, *args, **kwargs)\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0margs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_lower\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs_flat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_eval_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs_flat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mout_flat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompiled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprofiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_pjit_call_impl_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs_flat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0mout_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpjit_p\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs_flat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/jax/_src/pjit.py\u001b[0m in \u001b[0;36m_pjit_call_impl_python\u001b[0;34m(jaxpr, in_shardings, out_shardings, in_layouts, out_layouts, resource_env, donated_invars, name, keep_unused, inline, compiler_options_kvs, *args)\u001b[0m\n\u001b[1;32m   1670\u001b[0m       \u001b[0mpgle_profiler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpgle_profiler\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1671\u001b[0m       \u001b[0mcompiler_options_kvs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompiler_options_kvs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1672\u001b[0;31m   ).compile()\n\u001b[0m\u001b[1;32m   1673\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1674\u001b[0m   \u001b[0;31m# This check is expensive so only do it if enable_checks is on.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/jax/_src/interpreters/pxla.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, compiler_options)\u001b[0m\n\u001b[1;32m   2413\u001b[0m     \u001b[0mcompiler_options_kvs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiler_options_kvs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mt_compiler_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2414\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_executable\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mcompiler_options_kvs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2415\u001b[0;31m       executable = UnloadedMeshExecutable.from_hlo(\n\u001b[0m\u001b[1;32m   2416\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hlo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2417\u001b[0m           compiler_options_kvs=compiler_options_kvs)\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/jax/_src/interpreters/pxla.py\u001b[0m in \u001b[0;36mfrom_hlo\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   2921\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2922\u001b[0m     \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"pxla_cached_compilation\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2923\u001b[0;31m     xla_executable = _cached_compilation(\n\u001b[0m\u001b[1;32m   2924\u001b[0m         \u001b[0mhlo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmesh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspmd_lowering\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2925\u001b[0m         \u001b[0mtuple_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauto_spmd_lowering\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_prop_to_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/jax/_src/interpreters/pxla.py\u001b[0m in \u001b[0;36m_cached_compilation\u001b[0;34m(computation, name, mesh, spmd_lowering, tuple_args, auto_spmd_lowering, allow_prop_to_inputs, allow_prop_to_outputs, host_callbacks, backend, da, pmap_nreps, compiler_options_kvs, pgle_profiler)\u001b[0m\n\u001b[1;32m   2727\u001b[0m       \u001b[0;34m\"Finished XLA compilation of {fun_name} in {elapsed_time:.9f} sec\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2728\u001b[0m       fun_name=name, event=dispatch.BACKEND_COMPILE_EVENT):\n\u001b[0;32m-> 2729\u001b[0;31m     xla_executable = compiler.compile_or_get_cached(\n\u001b[0m\u001b[1;32m   2730\u001b[0m         \u001b[0mbackend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomputation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhost_callbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2731\u001b[0m         pgle_profiler)\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/jax/_src/compiler.py\u001b[0m in \u001b[0;36mcompile_or_get_cached\u001b[0;34m(backend, computation, devices, compile_options, host_callbacks, pgle_profiler)\u001b[0m\n\u001b[1;32m    450\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0mlog_persistent_cache_miss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m     return _compile_and_write_cache(\n\u001b[0m\u001b[1;32m    453\u001b[0m         \u001b[0mbackend\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m         \u001b[0mcomputation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/jax/_src/compiler.py\u001b[0m in \u001b[0;36m_compile_and_write_cache\u001b[0;34m(backend, computation, compile_options, host_callbacks, module_name, cache_key)\u001b[0m\n\u001b[1;32m    651\u001b[0m ) -> xc.LoadedExecutable:\n\u001b[1;32m    652\u001b[0m   \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 653\u001b[0;31m   executable = backend_compile(\n\u001b[0m\u001b[1;32m    654\u001b[0m       \u001b[0mbackend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomputation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhost_callbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    655\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/jax/_src/profiler.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    331\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mTraceAnnotation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mdecorator_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 333\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    334\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/jax/_src/compiler.py\u001b[0m in \u001b[0;36mbackend_compile\u001b[0;34m(backend, module, options, host_callbacks)\u001b[0m\n\u001b[1;32m    301\u001b[0m     \u001b[0;31m# TODO(sharadmv): remove this fallback when all backends allow `compile`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m     \u001b[0;31m# to take in `host_callbacks`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 303\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuilt_c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    304\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mxc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXlaRuntimeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0merror_handler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_XLA_RUNTIME_ERROR_HANDLERS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "solvers=[\"protes\", \"cem\", \"random\", \"exact_enum\", \"sa\", \"tabu\", \"qbsolv\"]\n",
        "problems=[\"maxcut_cardinality\", \"knapsack\", \"onehot_qubo\",\"portfolio\"]\n",
        "\n",
        "out,bench=run_experiment_main(\"onehot_qubo.yaml\")\n",
        "plot_history_main(out/\"history.csv\")\n",
        "\n",
        "Q=get_onehot_qubo(bench)\n",
        "ans=DWaveQuboSolver(Q)\n",
        "conf = ans.record.sample[0].astype(np.int8)\n",
        "E=ans.first.energy\n",
        "print('qubo solver ans')\n",
        "bench.print_results(conf)\n",
        "#HOME\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
